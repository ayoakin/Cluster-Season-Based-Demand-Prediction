{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "18c99d4094dd429f8fb0fc186cdb5777",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "Let's start with the initial data loading and exploratory data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "df4449b62c0b4945af6aa4b8c269d0de",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 1501,
    "execution_start": 1746958357953,
    "source_hash": "cc553829",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('SeoulBikeData.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df)\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "234d3f5c2d9048aaa6586f9e7e809bc5",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 868,
    "execution_start": 1746958366390,
    "source_hash": "b352ed8b",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create visualization for bike rentals by hour\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.boxplot(x='Hour', y='Rented Bike Count', data=df)\n",
    "plt.title('Distribution of Bike Rentals by Hour')\n",
    "plt.show()\n",
    "\n",
    "# Create visualization for bike rentals by season\n",
    "plt.figure(figsize=(10, 4))\n",
    "sns.boxplot(x='Seasons', y='Rented Bike Count', data=df)\n",
    "plt.title('Distribution of Bike Rentals by Season')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "correlation = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "40c20892df23411f8901e97c19f75026",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 106,
    "execution_start": 1746958378106,
    "source_hash": "d10bc0a",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Create cyclical features for Hour\n",
    "df['Hour_sin'] = np.sin(2 * np.pi * df['Hour']/24)\n",
    "df['Hour_cos'] = np.cos(2 * np.pi * df['Hour']/24)\n",
    "\n",
    "# Create interaction features\n",
    "df['Temp_Hour'] = df['Temperature(�C)'] * df['Hour']\n",
    "df['Humidity_Temp'] = df['Humidity(%)'] * df['Temperature(�C)']\n",
    "\n",
    "# Prepare categorical variables for one-hot encoding\n",
    "categorical_features = ['Seasons', 'Holiday', 'Functioning Day']\n",
    "numeric_features = ['Hour_sin', 'Hour_cos', 'Temperature(�C)', 'Humidity(%)',\n",
    "                   'Wind speed (m/s)', 'Visibility (10m)', 'Solar Radiation (MJ/m2)',\n",
    "                   'Rainfall(mm)', 'Snowfall (cm)', 'Temp_Hour', 'Humidity_Temp']\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse=False), categorical_features)\n",
    "    ])\n",
    "\n",
    "# Prepare X and y\n",
    "X = df[numeric_features + categorical_features]\n",
    "y = df['Rented Bike Count']\n",
    "\n",
    "# Split the data\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "\n",
    "# Fit and transform the data\n",
    "X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "X_val_transformed = preprocessor.transform(X_val)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "print(\"Transformed shapes:\")\n",
    "print(\"X_train:\", X_train_transformed.shape)\n",
    "print(\"X_val:\", X_val_transformed.shape)\n",
    "print(\"X_test:\", X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "a314522ec96b4ce29b49bbb78ae547c8",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 40776,
    "execution_start": 1746958387398,
    "source_hash": "faafa40d",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define learning rate schedule\n",
    "initial_learning_rate = 0.001\n",
    "decay_steps = 1000\n",
    "decay_rate = 0.9\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps, decay_rate\n",
    ")\n",
    "\n",
    "# Build the model\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(X_train_transformed.shape[1],)),\n",
    "    \n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.3),\n",
    "    \n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.BatchNormalization(),\n",
    "    layers.Dropout(0.2),\n",
    "    \n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "    loss='mse',\n",
    "    metrics=['mae']\n",
    ")\n",
    "\n",
    "# Define callbacks\n",
    "early_stopping = callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=15,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = callbacks.ModelCheckpoint(\n",
    "    'best_model.h5',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train_transformed, y_train,\n",
    "    validation_data=(X_val_transformed, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stopping, model_checkpoint],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "34d5f14d7c87447cae966a637dbc1ef5",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 656,
    "execution_start": 1746958438473,
    "source_hash": "c5245549",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# Evaluate Neural Network\n",
    "y_pred_nn = model.predict(X_test_transformed)\n",
    "mae_nn = mean_absolute_error(y_test, y_pred_nn)\n",
    "r2_nn = r2_score(y_test, y_pred_nn)\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['mae'], label='Training MAE')\n",
    "plt.plot(history.history['val_mae'], label='Validation MAE')\n",
    "plt.title('Model MAE')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for Neural Network predictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_nn, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Neural Network: Predicted vs Actual Values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNeural Network Metrics:\")\n",
    "print(f\"MAE: {mae_nn:.2f}\")\n",
    "print(f\"R²: {r2_nn:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "f1c1a48061cd4324821bd7532e1612bc",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 1376,
    "execution_start": 1746958449702,
    "source_hash": "3b04281",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Train Random Forest model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_model.predict(X_test_transformed)\n",
    "\n",
    "# Calculate metrics\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)\n",
    "\n",
    "# Scatter plot for Random Forest predictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_rf, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Random Forest: Predicted vs Actual Values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nRandom Forest Metrics:\")\n",
    "print(f\"MAE: {mae_rf:.2f}\")\n",
    "print(f\"R²: {r2_rf:.4f}\")\n",
    "\n",
    "# Compare models\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Neural Network', 'Random Forest'],\n",
    "    'MAE': [mae_nn, mae_rf],\n",
    "    'R²': [r2_nn, r2_rf]\n",
    "})\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Feature importance for Random Forest\n",
    "feature_names = numeric_features + [f\"{feat}_{cat}\" for feat, cats in \n",
    "                                  zip(categorical_features, preprocessor.named_transformers_['cat'].categories_) \n",
    "                                  for cat in cats[1:]]\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=importance_df.head(10))\n",
    "plt.title('Top 10 Most Important Features (Random Forest)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "0c4bea9e1bfc491ca2c1aff0f0dafff1",
    "deepnote_cell_type": "code",
    "deepnote_variable_name": "",
    "execution_context_id": "daad3cf6-6de1-4613-b1d8-0fc06d872d2c",
    "execution_millis": 357,
    "execution_start": 1746958464344,
    "source_hash": "4ec9cfc4",
    "sql_integration_id": ""
   },
   "outputs": [],
   "source": [
    "# Create and evaluate ensemble predictions\n",
    "y_pred_ensemble = (y_pred_nn.flatten() + y_pred_rf) / 2\n",
    "\n",
    "# Calculate ensemble metrics\n",
    "mae_ensemble = mean_absolute_error(y_test, y_pred_ensemble)\n",
    "r2_ensemble = r2_score(y_test, y_pred_ensemble)\n",
    "\n",
    "# Scatter plot for ensemble predictions\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test, y_pred_ensemble, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Ensemble: Predicted vs Actual Values')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Update comparison table with ensemble results\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Model': ['Neural Network', 'Random Forest', 'Ensemble'],\n",
    "    'MAE': [mae_nn, mae_rf, mae_ensemble],\n",
    "    'R²': [r2_nn, r2_rf, r2_ensemble]\n",
    "})\n",
    "print(\"\\nFinal Model Comparison:\")\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "0637521931544dc59cf0edcb3bf63d0c",
    "deepnote_cell_type": "text-cell-p",
    "formattedRanges": []
   },
   "source": [
    "The bike sharing demand prediction project has been completed. The ensemble model, combining both Neural Network and Random Forest predictions, achieved the best performance with an MAE of 140.39 and R² of 0.875. The Neural Network and Random Forest models performed similarly, with the Neural Network having a slightly better R² score. The feature importance analysis shows that temperature, hour-related features, and humidity are among the most important predictors for bike rental demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   },
   "source": [
    "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=3dc2a452-943f-4fc3-b0c9-21a20bef01eb' target=\"_blank\">\n",
    "<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\n",
    "Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>"
   ]
  }
 ],
 "metadata": {
  "deepnote_notebook_id": "67ad956e87a74813ac554d9f7d98f97b",
  "deepnote_persisted_session": {
   "createdAt": "2025-05-11T10:30:44.447Z"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
