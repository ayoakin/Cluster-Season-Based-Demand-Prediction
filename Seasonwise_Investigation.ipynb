{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M_rHR3pgJgu"
   },
   "source": [
    "# **Objectives and Hypotheses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ic2x8GRggQxg"
   },
   "source": [
    "## **Primary Hypotheses:**\n",
    "### Season-wise Hypothesis\n",
    "Can season-specific models better capture trends in bike demand than a unified model?\n",
    "\n",
    "## **Experimental Design:**\n",
    "### Baseline Model:\n",
    "XGBoost Regressor\n",
    "### Target Variable:\n",
    "Rented Bike Count\n",
    "### Dataset:\n",
    "Seoul Bike Sharing Demand\n",
    "### Data Split:\n",
    "80% training, 20% testing\n",
    "\n",
    "### Visualization:\n",
    "PCA for dimensionality reduction and cluster visualization\n",
    "\n",
    "### Performance Metrics:\n",
    "RMSE, MAE, and R²\n",
    "\n",
    "## **Expected Outcomes:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFkCZCB2WsRp"
   },
   "source": [
    "# **Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HsjQHFg_0Yz",
    "outputId": "0381b12f-74d3-4c89-cfd0-1316d5e81cc3"
   },
   "outputs": [],
   "source": [
    "pip install ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nfbZTdB_w0K"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "mpl.rcParams['axes.edgecolor'] = '#333333'\n",
    "mpl.rcParams['axes.linewidth'] = 0.8\n",
    "mpl.rcParams['xtick.color'] = '#333333'\n",
    "mpl.rcParams['ytick.color'] = '#333333'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6hwTLKoW-d_"
   },
   "source": [
    "# **Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sGCzaCo_7EK"
   },
   "outputs": [],
   "source": [
    "# Fetch Seoul Bike Sharing Demand dataset from UCI ML Repository\n",
    "seoul_bike_sharing_demand = fetch_ucirepo(id=560)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2TCiohL_-VU"
   },
   "outputs": [],
   "source": [
    "# Data (as pandas dataframes)\n",
    "X_original = seoul_bike_sharing_demand.data.features\n",
    "y_original = seoul_bike_sharing_demand.data.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kceoOc1_Cgpp",
    "outputId": "0cab3c4a-da7a-466b-bbbe-6cc34c0e864d"
   },
   "outputs": [],
   "source": [
    "# Print dataset information\n",
    "print(\"Dataset Metadata:\")\n",
    "print(seoul_bike_sharing_demand.metadata)\n",
    "print(\"\\nVariable Information:\")\n",
    "print(seoul_bike_sharing_demand.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXhCwGVOBWIE",
    "outputId": "54c641ae-6576-42b2-cd35-cb4c56a07089"
   },
   "outputs": [],
   "source": [
    "# Examine feature information\n",
    "print(\"\\nOriginal feature columns:\")\n",
    "print(X_original.columns.tolist())\n",
    "print(\"\\nOriginal target variable:\")\n",
    "print(y_original.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhRPHn3wXK2V"
   },
   "source": [
    "# **Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wY0aMkBoBtrX"
   },
   "outputs": [],
   "source": [
    "# Make 'Rented Bike Count' the new target if it exists\n",
    "\n",
    "if 'Rented Bike Count' in X_original.columns:\n",
    "    # Make 'Rented Bike Count' the new target\n",
    "    y = X_original[['Rented Bike Count']]\n",
    "    # Remove 'Rented Bike Count' from features\n",
    "    X = X_original.drop('Rented Bike Count', axis=1)\n",
    "    # Add original target to features\n",
    "    X = pd.concat([X, y_original], axis=1)\n",
    "\n",
    "else:\n",
    "    # If 'Rented Bike Count' is already the target, just confirm\n",
    "    print(\"'Rented Bike Count' is already the target variable.\")\n",
    "    y = y_original\n",
    "    X = X_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gpuLenjDAB_4",
    "outputId": "5aa10a1a-b8a6-436a-bd99-73bfe3ed4407"
   },
   "outputs": [],
   "source": [
    "print(\"\\nNew feature columns:\")\n",
    "print(X.columns.tolist())\n",
    "print(\"\\nNew target variable:\")\n",
    "print(y.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ELZ5f9cmAE0W",
    "outputId": "95d2874b-8e8d-4751-d7c2-57825f5d8884"
   },
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\nMissing values in features:\")\n",
    "print(X.isnull().sum())\n",
    "print(\"\\nMissing values in target:\")\n",
    "print(y.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dataset to investigate periodic data\n",
    "X_viz = X.copy()\n",
    "y_viz = y.copy()\n",
    "\n",
    "seasonal_data = X_viz.copy()\n",
    "seasonal_data['Rented_Bike_Count'] = y_viz['Rented Bike Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal Bike Demand Analysis\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Seasonal Bike Sharing Demand Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Prepare data\n",
    "seasonal_data = X_viz.copy()\n",
    "seasonal_data['Rented_Bike_Count'] = y_viz['Rented Bike Count']\n",
    "\n",
    "# Define season order\n",
    "season_order = ['Winter', 'Spring', 'Summer', 'Autumn']\n",
    "season_colors = ['#3498db', '#2ecc71', '#f39c12', '#e74c3c']  # Blue, Green, Orange, Red\n",
    "\n",
    "# 1. Average Daily Demand by Season\n",
    "seasonal_avg = seasonal_data.groupby('Seasons')['Rented_Bike_Count'].mean().reindex(season_order)\n",
    "\n",
    "bars = ax1.bar(seasonal_avg.index, seasonal_avg.values, \n",
    "               color=season_colors, alpha=0.8, edgecolor='#333333', linewidth=1.2)\n",
    "ax1.set_xlabel('Season', fontweight='bold')\n",
    "ax1.set_ylabel('Average Daily Bike Rentals', fontweight='bold')\n",
    "ax1.set_title('Average Daily Demand by Season', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "             f'{int(height)}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "# 2. Box plot showing distribution of demand by season\n",
    "seasonal_data_ordered = []\n",
    "season_labels = []\n",
    "for season in season_order:\n",
    "    season_data = seasonal_data[seasonal_data['Seasons'] == season]['Rented_Bike_Count']\n",
    "    if len(season_data) > 0:\n",
    "        seasonal_data_ordered.append(season_data)\n",
    "        season_labels.append(season)\n",
    "\n",
    "box_plot = ax2.boxplot(seasonal_data_ordered, tick_labels=season_labels, patch_artist=True)\n",
    "for patch, color in zip(box_plot['boxes'], season_colors[:len(season_labels)]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "\n",
    "ax2.set_xlabel('Season', fontweight='bold')\n",
    "ax2.set_ylabel('Daily Bike Rentals', fontweight='bold')\n",
    "ax2.set_title('Distribution of Daily Demand by Season', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print seasonal summary statistics\n",
    "print(\"Seasonal Bike Sharing Analysis\")\n",
    "\n",
    "for season in season_order:\n",
    "    season_data = seasonal_data[seasonal_data['Seasons'] == season]['Rented_Bike_Count']\n",
    "    if len(season_data) > 0:\n",
    "        print(f\"\\n{season}:\")\n",
    "        print(f\"  Average daily rentals: {season_data.mean():.1f}\")\n",
    "        print(f\"  Peak daily demand: {season_data.max():,}\")\n",
    "        print(f\"  Lowest daily demand: {season_data.min():,}\")\n",
    "        print(f\"  Standard deviation: {season_data.std():.1f}\")\n",
    "        print(f\"  Days of data: {len(season_data):,}\")\n",
    "\n",
    "# Compare seasons\n",
    "print(f\"\\nSeasonal Comparisons:\")\n",
    "\n",
    "# Find best and worst seasons\n",
    "season_averages = {}\n",
    "for season in season_order:\n",
    "    season_data = seasonal_data[seasonal_data['Seasons'] == season]['Rented_Bike_Count']\n",
    "    if len(season_data) > 0:\n",
    "        season_averages[season] = season_data.mean()\n",
    "\n",
    "if season_averages:\n",
    "    best_season = max(season_averages, key=season_averages.get)\n",
    "    worst_season = min(season_averages, key=season_averages.get)\n",
    "    \n",
    "    print(f\"Highest demand season: {best_season} ({season_averages[best_season]:.1f} avg daily)\")\n",
    "    print(f\"Lowest demand season: {worst_season} ({season_averages[worst_season]:.1f} avg daily)\")\n",
    "    \n",
    "    # Calculate difference\n",
    "    seasonal_range = season_averages[best_season] - season_averages[worst_season]\n",
    "    seasonal_range_pct = (seasonal_range / season_averages[worst_season]) * 100\n",
    "    \n",
    "    print(f\"Seasonal variation: {seasonal_range:.1f} rentals ({seasonal_range_pct:.1f}% increase from lowest to highest)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Bike Demand Over the Year\n",
    "fig, ax = plt.subplots(figsize=(15, 6))\n",
    "\n",
    "# Prepare data\n",
    "daily_data = X_viz.copy()\n",
    "daily_data['Rented_Bike_Count'] = y_viz['Rented Bike Count']\n",
    "\n",
    "# Convert Date to datetime if needed\n",
    "if daily_data['Date'].dtype == 'object':\n",
    "    daily_data['Date'] = pd.to_datetime(daily_data['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Group by date and sum hourly data to get daily totals\n",
    "daily_totals = daily_data.groupby('Date')['Rented_Bike_Count'].sum().reset_index()\n",
    "\n",
    "# Plot daily demand\n",
    "ax.plot(daily_totals['Date'], daily_totals['Rented_Bike_Count'], \n",
    "        color='#1f77b4', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Add a 7-day rolling average to smooth the trend\n",
    "if len(daily_totals) > 7:\n",
    "    rolling_avg = daily_totals['Rented_Bike_Count'].rolling(window=7, center=True).mean()\n",
    "    ax.plot(daily_totals['Date'], rolling_avg, \n",
    "            color='#ff7f0e', linewidth=2.5, label='7-Day Moving Average')\n",
    "    ax.legend()\n",
    "\n",
    "ax.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "ax.set_ylabel('Daily Bike Rentals', fontweight='bold', fontsize=12)\n",
    "ax.set_title('Daily Bike Demand Over the Year', fontweight='bold', fontsize=16)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Format x-axis to show months nicely\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cyclical Encoding\n",
    "For ML processes we often want to encode data for more efficient processing, however in this case, we need to choose an encoding which preserves the periodic patterns that will help us make our demand predictions. We can use a technique called Cyclical Encoding for the features in the dataset which are periodic in nature.  This will better help us capture seasonal, monthly, weekly and diurnal trends for our demand prediction.\n",
    "\n",
    "The technique is borrowed from harmonic analysis and signal processing, where we place our periodic data on a unite circle rather than on a linear scale.  This helps us preserve the natural relationships, for example, between Sunday and Monday, Decemeber and Janaury, which are now neighbors rather than distance points.\n",
    "\n",
    "This also helps smooth artificial jumps between time periods, for example between the first day of January and the last day of December, or between the end of Spring and the start of Summer.  The elegance here is that Euclidean distance in sin/cos space matches circular distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cyclical encoding for months and plot the difference\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Changed from (2, 3) to (1, 3)\n",
    "fig.suptitle('Cyclical Encoding Example: From Linear to Circular Representation', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Months of the year\n",
    "months = np.arange(1, 13)  # Jan=1 to Dec=12\n",
    "month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "               'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Linear representation\n",
    "axes[0].scatter(months, [0]*12, c=range(12), cmap='viridis', s=100)  # Changed from axes[0, 0] to axes[0]\n",
    "for i, name in enumerate(month_names):\n",
    "    axes[0].annotate(name, (months[i], 0), xytext=(0, 20), \n",
    "                       textcoords='offset points', ha='center')\n",
    "axes[0].set_xlabel('Month (Linear)', fontweight='bold')\n",
    "axes[0].set_title('Jan and Dec plotted linearly', fontweight='bold')\n",
    "axes[0].set_ylim(-0.5, 1)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Cyclical representation using sin/cos\n",
    "month_angles = 2 * np.pi * months / 12\n",
    "month_sin = np.sin(month_angles)\n",
    "month_cos = np.cos(month_angles)\n",
    "\n",
    "# Plot on unit circle\n",
    "circle = plt.Circle((0, 0), 1, fill=False, color='gray', linestyle='--', alpha=0.5)\n",
    "axes[1].add_patch(circle)  # Changed from axes[0, 1] to axes[1]\n",
    "axes[1].scatter(month_cos, month_sin, c=range(12), cmap='viridis', s=100)\n",
    "for i, name in enumerate(month_names):\n",
    "    axes[1].annotate(name, (month_cos[i], month_sin[i]), xytext=(5, 5), \n",
    "                       textcoords='offset points', fontsize=8)\n",
    "axes[1].set_xlabel('Month Cosine', fontweight='bold')\n",
    "axes[1].set_ylabel('Month Sine', fontweight='bold')\n",
    "axes[1].set_title('Jan and Dec are neighbors on the unit circle', fontweight='bold')\n",
    "axes[1].set_aspect('equal')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Encoding formulas\n",
    "axes[2].text(0.1, 0.8, 'Cyclical Encoding Formulas:', fontsize=14, fontweight='bold', transform=axes[2].transAxes)  # Changed from axes[0, 2] to axes[2]\n",
    "axes[2].text(0.1, 0.7, 'For month M (1-12):', fontsize=12, transform=axes[2].transAxes)\n",
    "axes[2].text(0.1, 0.6, 'angle = 2π × M / 12', fontsize=12, transform=axes[2].transAxes, family='monospace')\n",
    "axes[2].text(0.1, 0.5, 'month_sin = sin(angle)', fontsize=12, transform=axes[2].transAxes, family='monospace')\n",
    "axes[2].text(0.1, 0.4, 'month_cos = cos(angle)', fontsize=12, transform=axes[2].transAxes, family='monospace')\n",
    "axes[2].text(0.1, 0.25, 'Benefits:', fontsize=12, fontweight='bold', transform=axes[2].transAxes)\n",
    "axes[2].text(0.1, 0.15, '• Preserves cyclical relationships', fontsize=10, transform=axes[2].transAxes)\n",
    "axes[2].text(0.1, 0.1, '• Smooth transitions', fontsize=10, transform=axes[2].transAxes)\n",
    "axes[2].text(0.1, 0.05, '• No arbitrary ordering', fontsize=10, transform=axes[2].transAxes)\n",
    "axes[2].set_xlim(0, 1)\n",
    "axes[2].set_ylim(0, 1)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert periodic data to cyclical encoding\n",
    "def create_cyclical_encoding(X_data):\n",
    "    X_cyclical = X_data.copy()\n",
    "    \n",
    "    X_cyclical['Date'] = pd.to_datetime(X_cyclical['Date'])\n",
    "    \n",
    "    X_cyclical['Month_sin'] = np.sin(2 * np.pi * X_cyclical['Month'] / 12)\n",
    "    X_cyclical['Month_cos'] = np.cos(2 * np.pi * X_cyclical['Month'] / 12)\n",
    "    \n",
    "    X_cyclical['DayOfYear'] = X_cyclical['Date'].dt.dayofyear\n",
    "    X_cyclical['DayOfYear_sin'] = np.sin(2 * np.pi * X_cyclical['DayOfYear'] / 365)\n",
    "    X_cyclical['DayOfYear_cos'] = np.cos(2 * np.pi * X_cyclical['DayOfYear'] / 365)\n",
    "    \n",
    "    X_cyclical['Hour_sin'] = np.sin(2 * np.pi * X_cyclical['Hour'] / 24)\n",
    "    X_cyclical['Hour_cos'] = np.cos(2 * np.pi * X_cyclical['Hour'] / 24)\n",
    "    \n",
    "    X_cyclical['DayOfWeek_sin'] = np.sin(2 * np.pi * X_cyclical['DayOfWeek'] / 7)\n",
    "    X_cyclical['DayOfWeek_cos'] = np.cos(2 * np.pi * X_cyclical['DayOfWeek'] / 7)\n",
    "    \n",
    "    # Map seasons to numbers (0-3) in seasonal order\n",
    "    season_mapping = {\n",
    "        'Winter': 0,    # Start of cycle\n",
    "        'Spring': 1,    # 1/4 through cycle  \n",
    "        'Summer': 2,    # 1/2 through cycle\n",
    "        'Autumn': 3     # 3/4 through cycle\n",
    "    }\n",
    "    \n",
    "    # Create numeric season column\n",
    "    X_cyclical['Season_numeric'] = X_cyclical['Seasons'].map(season_mapping)\n",
    "    \n",
    "    # Create seasonal cyclical encoding\n",
    "    X_cyclical['Season_sin'] = np.sin(2 * np.pi * X_cyclical['Season_numeric'] / 4)\n",
    "    X_cyclical['Season_cos'] = np.cos(2 * np.pi * X_cyclical['Season_numeric'] / 4)    \n",
    "    \n",
    "    return X_cyclical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick reset to avoid returning to the start of the notebook\n",
    "seoul_bike_sharing_demand = fetch_ucirepo(id=560)\n",
    "X_original = seoul_bike_sharing_demand.data.features\n",
    "y_original = seoul_bike_sharing_demand.data.targets\n",
    "\n",
    "# Make 'Rented Bike Count' the new target if it exists\n",
    "\n",
    "if 'Rented Bike Count' in X_original.columns:\n",
    "    # Make 'Rented Bike Count' the new target\n",
    "    y = X_original[['Rented Bike Count']]\n",
    "    # Remove 'Rented Bike Count' from features\n",
    "    X = X_original.drop('Rented Bike Count', axis=1)\n",
    "    # Add original target to features\n",
    "    X = pd.concat([X, y_original], axis=1)\n",
    "\n",
    "else:\n",
    "    # If 'Rented Bike Count' is already the target, just confirm\n",
    "    print(\"'Rented Bike Count' is already the target variable.\")\n",
    "    y = y_original\n",
    "    X = X_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T0ZypEjpAjqO"
   },
   "outputs": [],
   "source": [
    "# 1. Convert date column to datetime and extract useful components. date format is DD/MM/YYYY\n",
    "if 'Date' in X.columns:\n",
    "    # Specify the correct date format as DD/MM/YYYY\n",
    "    X['Date'] = pd.to_datetime(X['Date'], format='%d/%m/%Y')\n",
    "    X['Year'] = X['Date'].dt.year\n",
    "    X['Month'] = X['Date'].dt.month\n",
    "    X['Day'] = X['Date'].dt.day\n",
    "    X['DayOfWeek'] = X['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create cyclical encoding before adding one-encoding\n",
    "X = create_cyclical_encoding(X)\n",
    "\n",
    "# Drop Date after cyclical encoding\n",
    "X = X.drop('Date', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "KyW3-YG4QpIi",
    "outputId": "f77d5bc5-2961-4612-b0ee-d04a297595d4"
   },
   "outputs": [],
   "source": [
    "# 3. Convert categorical features to numeric using one-hot encoding\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUXcIclqElR5"
   },
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 819
    },
    "id": "fMNS9RuVTF7w",
    "outputId": "1f6e6fda-0d94-4e95-a53e-976f0aa0e5ba"
   },
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train, columns=X_train.columns)\n",
    "\n",
    "correlation_matrix = X_train_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "# Use the calculated correlation matrix in the heatmap\n",
    "sns.heatmap(correlation_matrix, cmap='coolwarm', annot=False, fmt='.2f')\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual removal of collinear features, since cyclical features will have intentionally high VIF\n",
    "definitely_remove = [\"DayOfYear\", \"Month\", \"Day\", \"Dew point temperature\"]  \n",
    "X_train_filtered = X_train.drop(columns=[f for f in definitely_remove if f in X_train.columns])\n",
    "X_test_filtered = X_test.drop(columns=[f for f in definitely_remove if f in X_test.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P8x5rCrwUSxP"
   },
   "outputs": [],
   "source": [
    "# Standardize the filtered features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_filtered)\n",
    "X_test_scaled = scaler.transform(X_test_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bfs7TqaNXbmM"
   },
   "source": [
    "# **Model Development**\n",
    "We break development into the following steps:\n",
    "1. Create a baseline XGBoost model using default parameters\n",
    "2. Use hyperparameter tuning with regularization to optimize the model\n",
    "3. Implement early stopping to prevent overfitting\n",
    "4. Evaluate the results and create visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick Reset\n",
    "Before proceeding, let's create a quick way to start with fresh preprocessed data defined by our earlier scheme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    \"\"\"\n",
    "    Minimal preprocessing pipeline for bike sharing demand data\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    seoul_bike_sharing_demand = fetch_ucirepo(id=560)\n",
    "    X_original = seoul_bike_sharing_demand.data.features\n",
    "    y_original = seoul_bike_sharing_demand.data.targets\n",
    "    \n",
    "    # Handle target variable\n",
    "    if 'Rented Bike Count' in X_original.columns:\n",
    "        y = X_original[['Rented Bike Count']]\n",
    "        X = X_original.drop('Rented Bike Count', axis=1)\n",
    "        X = pd.concat([X, y_original], axis=1)\n",
    "    else:\n",
    "        y = y_original\n",
    "        X = X_original\n",
    "        \n",
    "    # Process dates and create cyclical features\n",
    "    if 'Date' in X.columns:\n",
    "        X['Date'] = pd.to_datetime(X['Date'], format='%d/%m/%Y')\n",
    "        X['Year'] = X['Date'].dt.year\n",
    "        X['Month'] = X['Date'].dt.month\n",
    "        X['Day'] = X['Date'].dt.day\n",
    "        X['DayOfWeek'] = X['Date'].dt.dayofweek\n",
    "        \n",
    "    # Create cyclical encoding and clean up\n",
    "    X = create_cyclical_encoding(X)\n",
    "    X = X.drop('Date', axis=1)\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Remove collinear features\n",
    "    definitely_remove = [\"DayOfYear\", \"Month\", \"Day\", \"Dew point temperature\"]\n",
    "    actually_removed = [f for f in definitely_remove if f in X_train.columns]\n",
    "    \n",
    "    if actually_removed:\n",
    "        X_train = X_train.drop(columns=actually_removed)\n",
    "        X_test = X_test.drop(columns=actually_removed)\n",
    "    \n",
    "    # Standardize\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, X_train.columns.tolist()\n",
    "\n",
    "# Run preprocessing\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_names = preprocess_data()\n",
    "print(f\"Data preprocessed: {len(feature_names)} features, {len(X_train_scaled)} training samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a Baseline Model and Check for Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# Train the baseline model\n",
    "baseline_model.fit(X_train_scaled, y_train.values.ravel())\n",
    "\n",
    "# Make predictions for baseline model\n",
    "baseline_train_preds = baseline_model.predict(X_train_scaled)\n",
    "baseline_test_preds = baseline_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics for baseline model\n",
    "baseline_metrics = {\n",
    "    'train_rmse': math.sqrt(mean_squared_error(y_train, baseline_train_preds)),\n",
    "    'train_r2': r2_score(y_train, baseline_train_preds),\n",
    "    'train_mae': mean_absolute_error(y_train, baseline_train_preds),\n",
    "    'test_rmse': math.sqrt(mean_squared_error(y_test, baseline_test_preds)),\n",
    "    'test_r2': r2_score(y_test, baseline_test_preds),\n",
    "    'test_mae': mean_absolute_error(y_test, baseline_test_preds)\n",
    "}\n",
    "\n",
    "print(\"BASELINE MODEL PERFORMANCE (Minimal Config):\")\n",
    "print(f\"Training RMSE:  {baseline_metrics['train_rmse']:.2f}\")\n",
    "print(f\"Training R²:    {baseline_metrics['train_r2']:.4f}\")\n",
    "print(f\"Training MAE:   {baseline_metrics['train_mae']:.2f}\")\n",
    "print(f\"Test RMSE:      {baseline_metrics['test_rmse']:.2f}\")\n",
    "print(f\"Test R²:        {baseline_metrics['test_r2']:.4f}\")\n",
    "print(f\"Test MAE:       {baseline_metrics['test_mae']:.2f}\")\n",
    "\n",
    "# Check for overfitting in baseline model\n",
    "baseline_rmse_gap = baseline_metrics['test_rmse'] - baseline_metrics['train_rmse']\n",
    "baseline_mae_gap = baseline_metrics['test_mae'] - baseline_metrics['train_mae']\n",
    "\n",
    "print(f\"\\nBaseline Model Overfitting Check:\")\n",
    "print(f\"RMSE Gap (Test - Train): {baseline_rmse_gap:.2f}\")\n",
    "print(f\"MAE Gap (Test - Train):  {baseline_mae_gap:.2f}\")\n",
    "\n",
    "if baseline_rmse_gap < 30:\n",
    "    print(\"Minimal overfitting detected (RMSE)\")\n",
    "elif baseline_rmse_gap < 60:\n",
    "    print(\"Moderate overfitting detected (RMSE)\")\n",
    "else:\n",
    "    print(\"Significant overfitting detected (RMSE)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the baseline model overfits our training data with a RMSE Gap more than 60, we leave that for now and address overfitting for both the baseline and tuned models in step three.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Perform Hyperparameter Tuning\n",
    "Here we set up and conduct hyperparameter tuning to identify the optimal values for predicting bike usage. \n",
    "\n",
    "A table of the key XGBoost hyperparameters that we will use to control different aspects of model training, is provided:\n",
    "| Parameter | Function | Impact |\n",
    "|:-----------|:----------|:--------|\n",
    "| `n_estimators` | Number of decision trees (rounds) | More trees = better fit |\n",
    "| `learning_rate` | Step size for each tree's update | Lower = slower, more stable |\n",
    "| `max_depth` | Maximum depth of each tree | Higher = more complex trees |\n",
    "| `min_child_weight` | Minimum samples in leaf nodes | Higher = prevents overfitting |\n",
    "| `reg_alpha` | L1 regularization (Lasso) | Higher = simpler model |\n",
    "| `reg_lambda` | L2 regularization (Ridge) | Higher = smoother predictions |\n",
    "| `subsample` | Fraction of samples per tree | Lower = more randomization |\n",
    "| `colsample_bytree` | Fraction of features per tree | Lower = reduces correlation |\n",
    "\n",
    "We can use gridsearch to evaluate different combinations of these parameters when we build our XGBoost decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define comprehensive parameter grid for tuned model with regularization focus\n",
    "param_grid_comprehensive = {\n",
    "    # Number of boosting rounds\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    \n",
    "    # Learning rate - conservative values to prevent overfitting\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    \n",
    "    # Tree structure - moderate depth to capture patterns without overfitting\n",
    "    'max_depth': [3, 4, 6],\n",
    "    \n",
    "    # Minimum child weight - higher values prevent overfitting\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    \n",
    "    # L1 regularization - encourages sparsity\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    \n",
    "    # L2 regularization - smooths predictions\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    \n",
    "    # Subsampling - reduces overfitting through randomization\n",
    "    'subsample': [0.7, 0.8, 0.9],\n",
    "    \n",
    "    # Feature subsampling - reduces correlation between trees\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Early Stopping with Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we address overfitting with the baseline model\n",
    "\n",
    "We can adjust our baseline model by adding hyperparameters, first we try adjusting the learning rate and tree depth:\n",
    "| Parameter | Function | Impact |\n",
    "|:-----------|:----------|:--------|\n",
    "| `n_estimators` | Number of decision trees (rounds) | More trees = better fit |\n",
    "| `learning_rate` | Step size for each tree's update | Lower = slower, more stable |\n",
    "| `max_depth` | Maximum depth of each tree | Higher = more complex trees |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_better_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train and evaluate baseline better model\n",
    "baseline_better_model.fit(X_train_scaled, y_train.values.ravel())\n",
    "baseline_better_train_preds = baseline_better_model.predict(X_train_scaled)\n",
    "baseline_better_test_preds = baseline_better_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics for baseline better model\n",
    "baseline_better_train_rmse = math.sqrt(mean_squared_error(y_train, baseline_better_train_preds))\n",
    "baseline_better_test_rmse = math.sqrt(mean_squared_error(y_test, baseline_better_test_preds))\n",
    "baseline_better_train_r2 = r2_score(y_train, baseline_better_train_preds)\n",
    "baseline_better_test_r2 = r2_score(y_test, baseline_better_test_preds)\n",
    "baseline_better_train_mae = mean_absolute_error(y_train, baseline_better_train_preds)\n",
    "baseline_better_test_mae = mean_absolute_error(y_test, baseline_better_test_preds)\n",
    "\n",
    "print(\"BASELINE BETTER MODEL PERFORMANCE: \\n(Adjusted tree depth and learning rate)\\n\")\n",
    "print(f\"Train RMSE: {baseline_better_train_rmse:.2f} | Test RMSE: {baseline_better_test_rmse:.2f}\")\n",
    "print(f\"Train R²:   {baseline_better_train_r2:.4f} | Test R²:   {baseline_better_test_r2:.4f}\")\n",
    "print(f\"Train MAE:  {baseline_better_train_mae:.2f} | Test MAE:  {baseline_better_test_mae:.2f}\")\n",
    "print(f\"RMSE Overfitting Gap: {baseline_better_test_rmse:.2f} - {baseline_better_train_rmse:.2f} = {baseline_better_test_rmse - baseline_better_train_rmse:.2f}\")\n",
    "print(f\"MAE Overfitting Gap:  {baseline_better_test_mae:.2f} - {baseline_better_train_mae:.2f} = {baseline_better_test_mae - baseline_better_train_mae:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This improved our overfitting reducing the gap from 91.59 to 55.37 in this new model with minimal regularization.  This model has moderate overfitting but is a huge improvement.  Still, we can do better by adding stronger regularization.\n",
    "| Parameter | Function | Impact |\n",
    "|:-----------|:----------|:--------|\n",
    "| `n_estimators` | Number of decision trees (rounds) | More trees = better fit |\n",
    "| `learning_rate` | Step size for each tree's update | Lower = slower, more stable |\n",
    "| `max_depth` | Maximum depth of each tree | Higher = more complex trees |\n",
    "| `min_child_weight` | Minimum samples in leaf nodes | Higher = prevents overfitting |\n",
    "| `reg_alpha` | L1 regularization (Lasso) | Higher = simpler model |\n",
    "| `reg_lambda` | L2 regularization (Ridge) | Higher = smoother predictions |\n",
    "| `subsample` | Fraction of samples per tree | Lower = more randomization |\n",
    "| `colsample_bytree` | Fraction of features per tree | Lower = reduces correlation |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced baseline with regularization to address overfitting\n",
    "baseline_best_model = xgb.XGBRegressor(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.08,          # Slightly lower\n",
    "    max_depth=5,                 # Reduced depth\n",
    "    min_child_weight=3,          # Higher minimum\n",
    "    reg_alpha=0.5,               # L1 regularization\n",
    "    reg_lambda=2,                # L2 regularization\n",
    "    subsample=0.8,               # Sample 80% of data\n",
    "    colsample_bytree=0.8,        # Sample 80% of features\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train and evaluate baseline best model\n",
    "baseline_best_model.fit(X_train_scaled, y_train.values.ravel())\n",
    "baseline_best_train_preds = baseline_best_model.predict(X_train_scaled)\n",
    "baseline_best_test_preds = baseline_best_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate metrics for baseline best model\n",
    "baseline_best_train_rmse = math.sqrt(mean_squared_error(y_train, baseline_best_train_preds))\n",
    "baseline_best_test_rmse = math.sqrt(mean_squared_error(y_test, baseline_best_test_preds))\n",
    "baseline_best_train_r2 = r2_score(y_train, baseline_best_train_preds)\n",
    "baseline_best_test_r2 = r2_score(y_test, baseline_best_test_preds)\n",
    "baseline_best_train_mae = mean_absolute_error(y_train, baseline_best_train_preds)\n",
    "baseline_best_test_mae = mean_absolute_error(y_test, baseline_best_test_preds)\n",
    "\n",
    "print(\"BASELINE BEST MODEL PERFORMANCE: \\n(With L1 and L2 Regularization, and adjusted learning rate and tree depth)\\n\")\n",
    "\n",
    "print(f\"Train RMSE: {baseline_best_train_rmse:.2f} | Test RMSE: {baseline_best_test_rmse:.2f}\")\n",
    "print(f\"Train R²:   {baseline_best_train_r2:.4f} | Test R²:   {baseline_best_test_r2:.4f}\")\n",
    "print(f\"Train MAE:  {baseline_best_train_mae:.2f} | Test MAE:  {baseline_best_test_mae:.2f}\")\n",
    "print(f\"RMSE Overfitting Gap: {baseline_best_test_rmse - baseline_best_train_rmse:.2f}\")\n",
    "print(f\"MAE Overfitting Gap:  {baseline_best_test_mae - baseline_best_train_mae:.2f}\")\n",
    "\n",
    "baseline_best_rmse_gap = baseline_best_test_rmse - baseline_best_train_rmse\n",
    "print(f\"\\nBaseline Best Model Improvement:\")\n",
    "print(f\"Gap Reduction vs Baseline: {(baseline_rmse_gap - baseline_best_rmse_gap):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use this new baseline model as it shows a significant improvement in generalization (34.38 is a much lower overfitting gap). . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a seasonally-aware model while staying vigiliant of overfitting\n",
    "To capture the complex seasonal interactions, we now turn to Grid Search to try to create a more seasonally-aware model. Our max depth parameter helps us capture complex seasonal interactions, reg_alpha and reg_lambda balance feature importance so cyclical features aren't overshadowed.  We adjust our learning rate so we can learn seasonal patterns slowly, and employ early stopping to ensure that the seasonally-aware model does not overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anti-overfitting parameter grid specifically designed for seasonal patterns\n",
    "param_grid_seasonal = {\n",
    "    # Conservative number of trees\n",
    "    'n_estimators': [100, 150, 200],\n",
    "    \n",
    "    # Lower learning rates for stable seasonal learning\n",
    "    'learning_rate': [0.01, 0.05, 0.08],\n",
    "    \n",
    "    # Moderate tree depths to capture seasonal interactions without overfitting\n",
    "    'max_depth': [4, 5, 6],\n",
    "    \n",
    "    # Higher minimum child weight for generalization\n",
    "    'min_child_weight': [3, 5, 7],\n",
    "    \n",
    "    # Strong L1 regularization for feature selection (helps cyclical features shine)\n",
    "    'reg_alpha': [0.5, 1.0, 2.0],\n",
    "    \n",
    "    # Strong L2 regularization for smooth predictions\n",
    "    'reg_lambda': [2, 3, 4],\n",
    "    \n",
    "    # Aggressive subsampling for randomization (prevents seasonal overfitting)\n",
    "    'subsample': [0.6, 0.7, 0.8],\n",
    "    'colsample_bytree': [0.6, 0.7, 0.8]\n",
    "}\n",
    "\n",
    "print(f\"Parameter combinations: {np.prod([len(v) for v in param_grid_seasonal.values()])}\")\n",
    "print(\"Focus: Optimize cyclical feature usage while preventing overfitting\")\n",
    "\n",
    "# Time Series Cross-Validation (preserves temporal relationships)\n",
    "tscv = TimeSeriesSplit(n_splits=5, test_size=len(X_train_scaled)//8)\n",
    "print(\"Using TimeSeriesSplit to respect temporal order in bike demand data\")\n",
    "\n",
    "# XGBoost configured for seasonal data\n",
    "xgb_seasonal = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0,\n",
    "    objective='reg:squarederror',\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "# Grid Search with seasonal focus\n",
    "grid_search_seasonal = GridSearchCV(\n",
    "    estimator=xgb_seasonal,\n",
    "    param_grid=param_grid_seasonal,\n",
    "    cv=tscv,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=7,   # number of cores to use (adjust for your system)\n",
    "    verbose=1,  # 0-suppress progress, 1-show minimal progress, 2-show progress with timing, 3- detailed progress\n",
    "    return_train_score=True\n",
    ")\n",
    "\n",
    "print(\"Starting seasonal-aware grid search...\")\n",
    "print(\"This will find optimal parameters for cyclical feature utilization, and will take some time to finish.\")\n",
    "print(\"Adjusting n_jobs can speed up the process based on the number of cores available.\")\n",
    "\n",
    "# Fit the grid search\n",
    "grid_search_seasonal.fit(X_train_scaled, y_train.values.ravel())\n",
    "\n",
    "print(\"Seasonal grid search completed!\")\n",
    "\n",
    "# Extract best results\n",
    "best_params_seasonal = grid_search_seasonal.best_params_\n",
    "best_cv_score = grid_search_seasonal.best_score_\n",
    "\n",
    "print(f\"\\nBEST SEASONAL PARAMETERS FROM GRID SEARCH:\")\n",
    "print(\"-\" * 45)\n",
    "for param, value in best_params_seasonal.items():\n",
    "    print(f\"{param:18s}: {value}\")\n",
    "\n",
    "print(f\"\\nGrid Search Results:\")\n",
    "print(f\"Best CV Score (Neg MSE): {best_cv_score:.2f}\")\n",
    "print(f\"Best CV RMSE: {math.sqrt(-best_cv_score):.2f}\")\n",
    "\n",
    "print(f\"\\nThese parameters will be used as starting point for manual tuning...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Tuning and Training of the Seasonal Model\n",
    "We used these grid search results as a starting point, and manually fine tuned the Regressor function to find a well tuned season model.  This involved using this and the following block to evaluate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"TRAINING SEASONAL MODEL WITH MANUAL TUNING + EARLY STOPPING\")\n",
    "\n",
    "# Create validation split for early stopping\n",
    "X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(\n",
    "    X_train_scaled, y_train.values.ravel(), test_size=0.15, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training split: {X_train_final.shape}\")\n",
    "print(f\"Validation split: {X_val_final.shape}\")\n",
    "\n",
    "print(f\"\\nManual tuning notes:\")\n",
    "print(\"Starting from grid search results, then fine-tuning based on:\")\n",
    "print(\"- Validation performance\")\n",
    "print(\"- Overfitting reduction\")\n",
    "print(\"- Cyclical feature importance\")\n",
    "\n",
    "# Seasonal model with manually tuned parameters (starting from grid search results)\n",
    "seasonal_model = xgb.XGBRegressor(\n",
    "    # Grid search starting points, then manually tuned:\n",
    "    n_estimators=280,           # More trees = higher overfitting risk (was 320, tried 250, 200, 150)\n",
    "    learning_rate=0.045,        # Moderate (was 0.05, tried 0.08, 0.03)\n",
    "    max_depth=6,                # Controls amount of complexity for cyclical features (was 5, tried 4)  \n",
    "    min_child_weight=3,         # Controls amount of complexity for cyclical features (was 2.5, tried 7)\n",
    "    reg_alpha=1.0,              # Controls overfitting (was 0.9, tried 0.7, 0.5, 2.5)  \n",
    "    reg_lambda=3.2,             # Controls overfitting (was 3.2, tried 2.0, 4.0)\n",
    "    subsample=0.82,             # Less aggressive (was 0.85, tried 0.8, 0.7, 0.6)\n",
    "    colsample_bytree=0.8,       # Helps cyclical features (was 0.85, tried 0.7, 0.6)\n",
    "    early_stopping_rounds=18,   # More patient (was 20, tried 25, 15, 8)\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(f\"\\nFinal tuned parameters:\")\n",
    "seasonal_params = {\n",
    "    'n_estimators': 280,\n",
    "    'learning_rate': 0.045,\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 3,\n",
    "    'reg_alpha': 1.0,\n",
    "    'reg_lambda': 3.2,\n",
    "    'subsample': 0.82,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'early_stopping_rounds': 18\n",
    "}\n",
    "\n",
    "for param, value in seasonal_params.items():\n",
    "    grid_search_value = best_params_seasonal.get(param, 'N/A')\n",
    "    print(f\"{param:20s}: {value} (grid search: {grid_search_value})\")\n",
    "\n",
    "# Train with early stopping validation\n",
    "print(f\"\\nTraining seasonal model with early stopping...\")\n",
    "seasonal_model.fit(\n",
    "    X_train_final, y_train_final,\n",
    "    eval_set=[(X_val_final, y_val_final)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(\"Seasonal model training completed!\")\n",
    "\n",
    "# Check early stopping results\n",
    "if hasattr(seasonal_model, 'best_iteration') and seasonal_model.best_iteration:\n",
    "    print(f\"Early stopping triggered at iteration: {seasonal_model.best_iteration}\")\n",
    "    trees_saved = 280 - seasonal_model.best_iteration\n",
    "    print(f\"Trees saved from overfitting: {trees_saved}\")\n",
    "    print(f\"Effective learning: Used {seasonal_model.best_iteration}/{280} trees ({(seasonal_model.best_iteration/280)*100:.1f}%)\")\n",
    "else:\n",
    "    print(f\"Used all 280 trees (early stopping didn't trigger)\")\n",
    "    print(\"Model may benefit from further regularization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on full train/test sets\n",
    "seasonal_train_preds = seasonal_model.predict(X_train_scaled)\n",
    "seasonal_test_preds = seasonal_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "seasonal_train_rmse = math.sqrt(mean_squared_error(y_train, seasonal_train_preds))\n",
    "seasonal_test_rmse = math.sqrt(mean_squared_error(y_test, seasonal_test_preds))\n",
    "seasonal_train_r2 = r2_score(y_train, seasonal_train_preds)\n",
    "seasonal_test_r2 = r2_score(y_test, seasonal_test_preds)\n",
    "seasonal_train_mae = mean_absolute_error(y_train, seasonal_train_preds)\n",
    "seasonal_test_mae = mean_absolute_error(y_test, seasonal_test_preds)\n",
    "\n",
    "print(f\"\\nSEASONAL MODEL PERFORMANCE:\")\n",
    "print(f\"Training RMSE:  {seasonal_train_rmse:.2f}\")\n",
    "print(f\"Training R²:    {seasonal_train_r2:.4f}\")\n",
    "print(f\"Training MAE:   {seasonal_train_mae:.2f}\")\n",
    "print(f\"Test RMSE:      {seasonal_test_rmse:.2f}\")\n",
    "print(f\"Test R²:        {seasonal_test_r2:.4f}\")\n",
    "print(f\"Test MAE:       {seasonal_test_mae:.2f}\")\n",
    "\n",
    "# Overfitting analysis with MAE and RMSE\n",
    "seasonal_rmse_gap = seasonal_test_rmse - seasonal_train_rmse\n",
    "seasonal_mae_gap = seasonal_test_mae - seasonal_train_mae\n",
    "\n",
    "print(f\"\\nOVERFITTING ANALYSIS:\")\n",
    "print(f\"RMSE Gap (Test - Train): {seasonal_rmse_gap:.2f}\")\n",
    "print(f\"MAE Gap (Test - Train):  {seasonal_mae_gap:.2f}\")\n",
    "\n",
    "# RMSE gap assessment\n",
    "if seasonal_rmse_gap < 30:\n",
    "    rmse_status = \"Excellent generalization achieved! (RMSE)\"\n",
    "elif seasonal_rmse_gap < 50:\n",
    "    rmse_status = \"Good generalization achieved! (RMSE)\"\n",
    "else:\n",
    "    rmse_status = \"Some overfitting remains - but model still usable (RMSE)\"\n",
    "\n",
    "# MAE gap assessment  \n",
    "if seasonal_mae_gap < 20:\n",
    "    mae_status = \"Excellent generalization achieved! (MAE)\"\n",
    "elif seasonal_mae_gap < 35:\n",
    "    mae_status = \"Good generalization achieved! (MAE)\"\n",
    "else:\n",
    "    mae_status = \"Some overfitting remains - but model still usable (MAE)\"\n",
    "\n",
    "print(f\"\\nGeneralization Assessment:\")\n",
    "print(f\"RMSE: {rmse_status}\")\n",
    "print(f\"MAE:  {mae_status}\")\n",
    "\n",
    "# Feature importance analysis focusing on cyclical features\n",
    "print(f\"\\nCYCLICAL FEATURE IMPORTANCE ANALYSIS:\")\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': seasonal_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Highlight cyclical features\n",
    "cyclical_features = feature_importance[feature_importance['feature'].str.contains('_sin|_cos')].head(8)\n",
    "\n",
    "if len(cyclical_features) > 0:\n",
    "    print(f\"Top cyclical features in seasonal model:\")\n",
    "    for i, (_, row) in enumerate(cyclical_features.iterrows(), 1):\n",
    "        print(f\"  {i}. {row['feature']:<20s}: {row['importance']:.4f}\")\n",
    "        \n",
    "    cyclical_importance_sum = cyclical_features['importance'].sum()\n",
    "    total_importance = feature_importance['importance'].sum()\n",
    "    cyclical_percentage = (cyclical_importance_sum / total_importance) * 100\n",
    "    \n",
    "    print(f\"\\nCyclical features account for {cyclical_percentage:.1f}% of total importance\")\n",
    "    \n",
    "    if cyclical_percentage > 15:\n",
    "        print(\"Seasonal patterns successfully captured!\")\n",
    "    elif cyclical_percentage > 10:\n",
    "        print(\"Moderate seasonal pattern usage\")\n",
    "    else:\n",
    "        print(\"Low cyclical feature importance - check feature engineering\")\n",
    "else:\n",
    "    print(\"No cyclical features found in top importance - check feature engineering\")\n",
    "\n",
    "# Model readiness assessment\n",
    "print(f\"\\nMODEL READINESS ASSESSMENT:\")\n",
    "print(f\"Seasonal model trained with {len(feature_names)} features\")\n",
    "print(f\"Grid search + manual tuning completed\")\n",
    "print(f\"Early stopping applied (saved {280 - (seasonal_model.best_iteration or 280)} trees)\")\n",
    "print(f\"Overfitting controlled: RMSE gap = {seasonal_rmse_gap:.2f}, MAE gap = {seasonal_mae_gap:.2f}\")\n",
    "print(f\"Cyclical features utilized: {cyclical_percentage:.1f}% importance\")\n",
    "\n",
    "# Store predictions for comparison charts\n",
    "print(f\"\\nPrediction arrays available:\")\n",
    "print(f\"- seasonal_train_preds: {len(seasonal_train_preds)} training predictions\")  \n",
    "print(f\"- seasonal_test_preds: {len(seasonal_test_preds)} test predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IjdW7iiSgAOi"
   },
   "source": [
    "## 4. Evaluation and Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly X-axis with Seasonal Lines and Background Colors\n",
    "def create_seasonal_plot():\n",
    "    # Prepare combined data\n",
    "    y_actual_all = np.concatenate([y_train.values.ravel(), y_test.values.ravel()])\n",
    "    y_pred_all = np.concatenate([balanced_train_preds, balanced_test_preds])\n",
    "    \n",
    "    # Create correct date range: Dec 1, 2017 to Nov 30, 2018 (8760 hours)\n",
    "    start_date = pd.Timestamp('2017-12-01')  # December 1, 2017\n",
    "    dates = pd.date_range(start=start_date, periods=len(y_actual_all), freq='h')\n",
    "    \n",
    "    # Create DataFrame with correct dates\n",
    "    df_combined = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Actual': y_actual_all,\n",
    "        'Predicted': y_pred_all\n",
    "    })\n",
    "    \n",
    "    # Aggregate to weekly (use 'W-THU' to end weeks on Thursday, closer to your data range)\n",
    "    df_weekly = df_combined.set_index('Date').resample('W-THU').mean().reset_index()\n",
    "    \n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(16, 8))\n",
    "    \n",
    "    # Define season colors\n",
    "    season_colors = {'Spring': '#90EE90', 'Summer': '#FFD700', 'Fall': '#FFA500', 'Winter': '#87CEEB'}\n",
    "    \n",
    "    # Create seasonal background blocks using correct data range\n",
    "    data_start = df_weekly['Date'].min()\n",
    "    data_end = df_weekly['Date'].max()\n",
    "    \n",
    "    print(f\"Actual data range: {data_start.strftime('%m/%d/%Y')} to {data_end.strftime('%m/%d/%Y')}\")\n",
    "    \n",
    "    season_patches = {}\n",
    "    \n",
    "    # Define seasonal boundaries for the actual data period (Dec 2017 - Nov 2018)\n",
    "    seasons = [\n",
    "        # Fall 2017: Dec 1, 2017 - Dec 21, 2017 (data starts in fall)\n",
    "        (pd.Timestamp('2017-12-01'), pd.Timestamp('2017-12-21'), 'Fall'),\n",
    "        # Winter 2017-2018: Dec 22, 2017 - Mar 20, 2018\n",
    "        (pd.Timestamp('2017-12-22'), pd.Timestamp('2018-03-20'), 'Winter'),\n",
    "        # Spring 2018: Mar 21, 2018 - Jun 21, 2018  \n",
    "        (pd.Timestamp('2018-03-21'), pd.Timestamp('2018-06-21'), 'Spring'),\n",
    "        # Summer 2018: Jun 22, 2018 - Sep 22, 2018\n",
    "        (pd.Timestamp('2018-06-22'), pd.Timestamp('2018-09-22'), 'Summer'),\n",
    "        # Fall 2018: Sep 23, 2018 - Nov 30, 2018\n",
    "        (pd.Timestamp('2018-09-23'), pd.Timestamp('2018-11-30'), 'Fall')\n",
    "    ]\n",
    "    \n",
    "    for season_start, season_end, season_name in seasons:\n",
    "        # Clip to actual data range\n",
    "        plot_start = max(season_start, data_start)\n",
    "        plot_end = min(season_end, data_end)\n",
    "        \n",
    "        if plot_start < plot_end:\n",
    "            patch = ax.axvspan(plot_start, plot_end, alpha=0.25, \n",
    "                             color=season_colors[season_name], zorder=0)\n",
    "            if season_name not in season_patches:  # Only keep first occurrence for legend\n",
    "                season_patches[season_name] = patch\n",
    "    \n",
    "    # Plot actual and predicted lines\n",
    "    ax.plot(df_weekly['Date'], df_weekly['Actual'], \n",
    "            color='#1f77b4', linewidth=2, alpha=0.8, label='Actual', zorder=2)\n",
    "    ax.plot(df_weekly['Date'], df_weekly['Predicted'], \n",
    "            color='#ff4444', linewidth=2, alpha=0.8, label='Predictions', zorder=2)\n",
    "    \n",
    "    # Add train/test split line\n",
    "    train_size = len(y_train)\n",
    "    total_size = len(y_actual_all)\n",
    "    split_ratio = train_size / total_size\n",
    "    split_week_idx = int(len(df_weekly) * split_ratio)\n",
    "    \n",
    "    if split_week_idx < len(df_weekly):\n",
    "        split_date = df_weekly.iloc[split_week_idx]['Date']\n",
    "        ax.axvline(x=split_date, color='green', linestyle='--', alpha=0.7, linewidth=2,\n",
    "                  label=f'Train/Test Split ({split_date.strftime(\"%m/%d/%Y\")})', zorder=1)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Date', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Weekly Average Bikes Shared', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Weekly Bike Demand: Actual vs Predicted with Seasonal Backgrounds', fontweight='bold', fontsize=14)\n",
    "    \n",
    "    # Create legend\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    \n",
    "    # Add seasonal patches to legend in chronological order (starting with Fall since data begins Dec 1)\n",
    "    for season in ['Fall', 'Winter', 'Spring', 'Summer']:\n",
    "        if season in season_patches:\n",
    "            handles.append(season_patches[season])\n",
    "            labels.append(f'{season} Season')\n",
    "    \n",
    "    ax.legend(handles, labels, loc='upper right', frameon=True, fancybox=True, shadow=True, fontsize=11)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Format x-axis to show month names in M/D/YYYY format\n",
    "    from matplotlib.dates import DateFormatter, MonthLocator\n",
    "    ax.xaxis.set_major_locator(MonthLocator())\n",
    "    ax.xaxis.set_major_formatter(DateFormatter('%m/%d/%Y'))\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Weekly Time Series Statistics:\")\n",
    "    print(f\"Total weeks: {len(df_weekly)}\")\n",
    "\n",
    "# Call the function to create the plot\n",
    "create_seasonal_plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize model performance by season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seasonal_bar_comparison():\n",
    "    \"\"\"Create actual vs predicted bar chart by season using seasonal model\"\"\"\n",
    "    # Prepare combined data using seasonal model predictions\n",
    "    y_actual_all = np.concatenate([y_train.values.ravel(), y_test.values.ravel()])\n",
    "    y_pred_all = np.concatenate([seasonal_train_preds, seasonal_test_preds])\n",
    "    \n",
    "    # Create correct date range: Dec 1, 2017 to Nov 30, 2018\n",
    "    start_date = pd.Timestamp('2017-12-01')\n",
    "    dates = pd.date_range(start=start_date, periods=len(y_actual_all), freq='h')\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_combined = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Actual': y_actual_all,\n",
    "        'Predicted': y_pred_all\n",
    "    })\n",
    "    \n",
    "    # Add season column\n",
    "    def get_season(date):\n",
    "        if (date.month == 12 and date.day >= 22) or date.month in [1, 2] or (date.month == 3 and date.day <= 20):\n",
    "            return 'Winter'\n",
    "        elif (date.month == 3 and date.day >= 21) or date.month in [4, 5] or (date.month == 6 and date.day <= 21):\n",
    "            return 'Spring'\n",
    "        elif (date.month == 6 and date.day >= 22) or date.month in [7, 8] or (date.month == 9 and date.day <= 22):\n",
    "            return 'Summer'\n",
    "        else:\n",
    "            return 'Fall'\n",
    "    \n",
    "    df_combined['Season'] = df_combined['Date'].apply(get_season)\n",
    "    \n",
    "    # Group by season and calculate means\n",
    "    seasonal_summary = df_combined.groupby('Season')[['Actual', 'Predicted']].mean().round(1)\n",
    "    \n",
    "    # Reorder seasons chronologically (starting with Fall since data begins Dec 1)\n",
    "    season_order = ['Fall', 'Winter', 'Spring', 'Summer']\n",
    "    seasonal_summary = seasonal_summary.reindex(season_order)\n",
    "    \n",
    "    # Create bar plot with room for legend\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    x = np.arange(len(seasonal_summary))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, seasonal_summary['Actual'], width, \n",
    "                   label='Actual', color='#1f77b4', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, seasonal_summary['Predicted'], width,\n",
    "                   label='Predicted', color='#ff4444', alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.0f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.0f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    # Formatting with extended y-axis to make room for legend\n",
    "    ax.set_xlabel('Season', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Average Bikes Shared', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Seasonal Model: Bike Demand by Season (Actual vs Predicted)', fontweight='bold', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(seasonal_summary.index)\n",
    "    \n",
    "    # Set y-axis limit to 800 to make room for legend in upper right\n",
    "    ax.set_ylim(0, 800)\n",
    "    \n",
    "    # Place legend in upper right\n",
    "    ax.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"Seasonal Model Performance Summary:\")\n",
    "    print(\"=\" * 45)\n",
    "    print(seasonal_summary)\n",
    "    \n",
    "    # Calculate seasonal errors\n",
    "    seasonal_errors = seasonal_summary['Predicted'] - seasonal_summary['Actual']\n",
    "    print(f\"\\nSeasonal Prediction Errors:\")\n",
    "    for season in seasonal_summary.index:\n",
    "        error = seasonal_errors[season]\n",
    "        print(f\"{season:8s}: {error:+6.1f} bikes\")\n",
    "    \n",
    "    return seasonal_summary\n",
    "\n",
    "seasonal_ = create_seasonal_bar_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize model performance by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "8TBV4heIGz7p",
    "outputId": "27e166d7-77f1-4b7e-9b6d-b5d537374bd0"
   },
   "outputs": [],
   "source": [
    "def create_monthly_bar_comparison():\n",
    "    \"\"\"Create actual vs predicted bar chart by month using seasonal model\"\"\"\n",
    "    # Prepare combined data using seasonal model predictions\n",
    "    y_actual_all = np.concatenate([y_train.values.ravel(), y_test.values.ravel()])\n",
    "    y_pred_all = np.concatenate([seasonal_train_preds, seasonal_test_preds])\n",
    "    \n",
    "    # Create correct date range: Dec 1, 2017 to Nov 30, 2018\n",
    "    start_date = pd.Timestamp('2017-12-01')\n",
    "    dates = pd.date_range(start=start_date, periods=len(y_actual_all), freq='h')\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df_combined = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Actual': y_actual_all,\n",
    "        'Predicted': y_pred_all\n",
    "    })\n",
    "    \n",
    "    # Add month column\n",
    "    df_combined['Month'] = df_combined['Date'].dt.month\n",
    "    df_combined['MonthName'] = df_combined['Date'].dt.strftime('%b')\n",
    "    \n",
    "    # Group by month and calculate means\n",
    "    monthly_summary = df_combined.groupby(['Month', 'MonthName'])[['Actual', 'Predicted']].mean().round(1)\n",
    "    monthly_summary = monthly_summary.reset_index()\n",
    "    \n",
    "    # Sort by chronological order (starting from December)\n",
    "    month_order = [12, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]  # Dec 2017 through Nov 2018\n",
    "    monthly_summary['Order'] = monthly_summary['Month'].map({m: i for i, m in enumerate(month_order)})\n",
    "    monthly_summary = monthly_summary.sort_values('Order')\n",
    "    \n",
    "    # Create bar plot\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    \n",
    "    x = np.arange(len(monthly_summary))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = ax.bar(x - width/2, monthly_summary['Actual'], width, \n",
    "                   label='Actual', color='#1f77b4', alpha=0.8)\n",
    "    bars2 = ax.bar(x + width/2, monthly_summary['Predicted'], width,\n",
    "                   label='Predicted', color='#ff4444', alpha=0.8)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars1:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.0f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    for bar in bars2:\n",
    "        height = bar.get_height()\n",
    "        ax.annotate(f'{height:.0f}',\n",
    "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    # Formatting with extended y-axis and upper left legend\n",
    "    ax.set_xlabel('Month', fontweight='bold', fontsize=12)\n",
    "    ax.set_ylabel('Average Bikes Shared', fontweight='bold', fontsize=12)\n",
    "    ax.set_title('Seasonal Model: Monthly Bike Demand (Dec 2017 - Nov 2018)', fontweight='bold', fontsize=14)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(monthly_summary['MonthName'])\n",
    "    \n",
    "    # Set y-axis limit to 850 and place legend in upper right\n",
    "    ax.set_ylim(0, 850)\n",
    "    ax.legend(loc='upper right', fontsize=12, frameon=True, fancybox=True, shadow=True)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(\"Monthly Performance Summary:\")\n",
    "    print(\"=\" * 50)\n",
    "    monthly_display = monthly_summary[['MonthName', 'Actual', 'Predicted']].copy()\n",
    "    monthly_display.columns = ['Month', 'Actual', 'Predicted']\n",
    "    print(monthly_display.to_string(index=False))\n",
    "    \n",
    "    # Calculate monthly errors\n",
    "    monthly_summary['Error'] = monthly_summary['Predicted'] - monthly_summary['Actual']\n",
    "    print(f\"\\nMonthly Prediction Errors:\")\n",
    "    for _, row in monthly_summary.iterrows():\n",
    "        print(f\"{row['MonthName']:8s}: {row['Error']:+6.1f} bikes\")\n",
    "    \n",
    "    return monthly_summary\n",
    "\n",
    "monthly_bars = create_monthly_bar_comparison()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated model comparison using new naming convention\n",
    "\n",
    "# Baseline Best model metrics (regularized baseline)\n",
    "baseline_best_train_rmse = math.sqrt(mean_squared_error(y_train, baseline_best_train_preds))\n",
    "baseline_best_test_rmse = math.sqrt(mean_squared_error(y_test, baseline_best_test_preds))\n",
    "baseline_best_train_mae = mean_absolute_error(y_train, baseline_best_train_preds)\n",
    "baseline_best_test_mae = mean_absolute_error(y_test, baseline_best_test_preds)\n",
    "\n",
    "# Seasonal model metrics (final tuned model)\n",
    "seasonal_train_rmse = math.sqrt(mean_squared_error(y_train, seasonal_train_preds))\n",
    "seasonal_test_rmse = math.sqrt(mean_squared_error(y_test, seasonal_test_preds))\n",
    "seasonal_train_mae = mean_absolute_error(y_train, seasonal_train_preds)\n",
    "seasonal_test_mae = mean_absolute_error(y_test, seasonal_test_preds)\n",
    "\n",
    "# R² scores\n",
    "baseline_best_train_r2 = r2_score(y_train, baseline_best_train_preds)\n",
    "baseline_best_test_r2 = r2_score(y_test, baseline_best_test_preds)\n",
    "seasonal_train_r2 = r2_score(y_train, seasonal_train_preds)\n",
    "seasonal_test_r2 = r2_score(y_test, seasonal_test_preds)\n",
    "\n",
    "# Create the comparison chart\n",
    "plt.figure(figsize=(16, 6))\n",
    "fig = plt.gcf()\n",
    "fig.patch.set_facecolor('#f8f9fa')\n",
    "\n",
    "# Define colors\n",
    "colors = ['#39A0ED', '#FF5E5B']  # Blue for Baseline, Coral for Final\n",
    "\n",
    "# Model names\n",
    "models = ['Baseline\\nBest', 'Seasonal\\nModel']\n",
    "\n",
    "# R² comparison (subplot 1)\n",
    "plt.subplot(1, 3, 1)\n",
    "r2_values = [baseline_best_test_r2, seasonal_test_r2]\n",
    "bars1 = plt.bar(models, r2_values, color=colors,\n",
    "               edgecolor='white', linewidth=0.8, width=0.7)\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar in bars1:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
    "            f'{height:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.title('Test R² Comparison\\n(higher is better)', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('Test R²', fontsize=12, color='#333333')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add best performance line\n",
    "max_r2 = max(r2_values)\n",
    "plt.axhline(y=max_r2, color='#333333', linestyle='--', alpha=0.5)\n",
    "plt.text(len(models)-1, max_r2 - 0.01, f'Best: {max_r2:.4f}',\n",
    "         ha='right', va='top', color='#333333', alpha=0.7, fontweight='bold')\n",
    "\n",
    "# RMSE comparison (subplot 2)\n",
    "plt.subplot(1, 3, 2)\n",
    "test_rmse_values = [baseline_best_test_rmse, seasonal_test_rmse]\n",
    "bars2 = plt.bar(models, test_rmse_values, color=colors,\n",
    "               edgecolor='white', linewidth=0.8, width=0.7)\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar in bars2:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "            f'{height:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.title('Test RMSE Comparison\\n(lower is better)', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('Test RMSE', fontsize=12, color='#333333')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add best performance line\n",
    "min_rmse = min(test_rmse_values)\n",
    "plt.axhline(y=min_rmse, color='#333333', linestyle='--', alpha=0.5)\n",
    "plt.text(len(models)-1, min_rmse + min_rmse*0.05, f'Best: {min_rmse:.2f}',\n",
    "         ha='right', va='bottom', color='#333333', alpha=0.7, fontweight='bold')\n",
    "\n",
    "# MAE comparison (subplot 3)\n",
    "plt.subplot(1, 3, 3)\n",
    "mae_values = [baseline_best_test_mae, seasonal_test_mae]\n",
    "bars3 = plt.bar(models, mae_values, color=colors,\n",
    "               edgecolor='white', linewidth=0.8, width=0.7)\n",
    "\n",
    "# Add values on top of bars\n",
    "for bar in bars3:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
    "            f'{height:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "\n",
    "plt.title('Test MAE Comparison\\n(lower is better)', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('Test MAE', fontsize=12, color='#333333')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add best performance line\n",
    "min_mae = min(mae_values)\n",
    "plt.axhline(y=min_mae, color='#333333', linestyle='--', alpha=0.5)\n",
    "plt.text(len(models)-1, min_mae + min_mae*0.05, f'Best: {min_mae:.2f}',\n",
    "         ha='right', va='bottom', color='#333333', alpha=0.7, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary comparison\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Metric':<15} {'Baseline':<12} {'Final Model':<12} {'Winner':<10}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Test R²':<15} {baseline_best_test_r2:<12.4f} {seasonal_test_r2:<12.4f} {'Seasonal' if seasonal_test_r2 > baseline_best_test_r2 else 'Baseline Best':<10}\")\n",
    "print(f\"{'Test RMSE':<15} {baseline_best_test_rmse:<12.2f} {seasonal_test_rmse:<12.2f} {'Seasonal' if seasonal_test_rmse < baseline_best_test_rmse else 'Baseline Best':<10}\")\n",
    "print(f\"{'Test MAE':<15} {baseline_best_test_mae:<12.2f} {seasonal_test_mae:<12.2f} {'Seasonal' if seasonal_test_mae < baseline_best_test_mae else 'Baseline Best':<10}\")\n",
    "\n",
    "# Calculate improvements\n",
    "r2_improvement = ((seasonal_test_r2 - baseline_best_test_r2) / baseline_best_test_r2) * 100\n",
    "rmse_improvement = ((baseline_best_test_rmse - seasonal_test_rmse) / baseline_best_test_rmse) * 100\n",
    "mae_improvement = ((baseline_best_test_mae - seasonal_test_mae) / baseline_best_test_mae) * 100\n",
    "\n",
    "print(f\"\\nImprovements (Seasonal vs Baseline Best):\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"R² improvement:   {r2_improvement:+6.2f}%\")\n",
    "print(f\"RMSE improvement: {rmse_improvement:+6.2f}%\")\n",
    "print(f\"MAE improvement:  {mae_improvement:+6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring overfitting improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for all four models using new naming convention\n",
    "\n",
    "# Model 1: Baseline Model (minimal configuration)\n",
    "baseline_train_rmse = math.sqrt(mean_squared_error(y_train, baseline_train_preds))\n",
    "baseline_test_rmse = math.sqrt(mean_squared_error(y_test, baseline_test_preds))\n",
    "baseline_train_mae = mean_absolute_error(y_train, baseline_train_preds)\n",
    "baseline_test_mae = mean_absolute_error(y_test, baseline_test_preds)\n",
    "\n",
    "# Model 2: Baseline Better Model (basic hyperparameters)\n",
    "baseline_better_train_rmse = math.sqrt(mean_squared_error(y_train, baseline_better_train_preds))\n",
    "baseline_better_test_rmse = math.sqrt(mean_squared_error(y_test, baseline_better_test_preds))\n",
    "baseline_better_train_mae = mean_absolute_error(y_train, baseline_better_train_preds)\n",
    "baseline_better_test_mae = mean_absolute_error(y_test, baseline_better_test_preds)\n",
    "\n",
    "# Model 3: Baseline Best Model (regularized)\n",
    "baseline_best_train_rmse = math.sqrt(mean_squared_error(y_train, baseline_best_train_preds))\n",
    "baseline_best_test_rmse = math.sqrt(mean_squared_error(y_test, baseline_best_test_preds))\n",
    "baseline_best_train_mae = mean_absolute_error(y_train, baseline_best_train_preds)\n",
    "baseline_best_test_mae = mean_absolute_error(y_test, baseline_best_test_preds)\n",
    "\n",
    "# Model 4: Seasonal Model (grid search + manual tuning + early stopping)\n",
    "seasonal_train_rmse = math.sqrt(mean_squared_error(y_train, seasonal_train_preds))\n",
    "seasonal_test_rmse = math.sqrt(mean_squared_error(y_test, seasonal_test_preds))\n",
    "seasonal_train_mae = mean_absolute_error(y_train, seasonal_train_preds)\n",
    "seasonal_test_mae = mean_absolute_error(y_test, seasonal_test_preds)\n",
    "\n",
    "# Calculate overfitting gaps\n",
    "baseline_rmse_gap = baseline_test_rmse - baseline_train_rmse\n",
    "baseline_better_rmse_gap = baseline_better_test_rmse - baseline_better_train_rmse\n",
    "baseline_best_rmse_gap = baseline_best_test_rmse - baseline_best_train_rmse\n",
    "seasonal_rmse_gap = seasonal_test_rmse - seasonal_train_rmse\n",
    "\n",
    "baseline_mae_gap = baseline_test_mae - baseline_train_mae\n",
    "baseline_better_mae_gap = baseline_better_test_mae - baseline_better_train_mae\n",
    "baseline_best_mae_gap = baseline_best_test_mae - baseline_best_train_mae\n",
    "seasonal_mae_gap = seasonal_test_mae - seasonal_train_mae\n",
    "\n",
    "# Create the overfitting comparison chart\n",
    "plt.figure(figsize=(16, 10))\n",
    "fig = plt.gcf()\n",
    "fig.patch.set_facecolor('#f8f9fa')\n",
    "\n",
    "# Define colors for model progression\n",
    "colors = ['#FF6B6B', '#FFA07A', '#4ECDC4', '#45B7D1']  # Red → Orange → Teal → Blue\n",
    "\n",
    "# Model names\n",
    "models = ['Baseline\\nModel', 'Baseline\\nBetter', 'Baseline\\nBest', 'Seasonal\\nModel']\n",
    "\n",
    "# Training vs Test RMSE (subplot 1)\n",
    "plt.subplot(2, 2, 1)\n",
    "train_rmse_values = [baseline_train_rmse, baseline_better_train_rmse, baseline_best_train_rmse, seasonal_train_rmse]\n",
    "test_rmse_values = [baseline_test_rmse, baseline_better_test_rmse, baseline_best_test_rmse, seasonal_test_rmse]\n",
    "\n",
    "x = np.arange(len(models))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = plt.bar(x - width/2, train_rmse_values, width, label='Train RMSE', \n",
    "                color=[c for c in colors], alpha=0.7, edgecolor='white', linewidth=0.8)\n",
    "bars2 = plt.bar(x + width/2, test_rmse_values, width, label='Test RMSE',\n",
    "                color=[c for c in colors], alpha=1.0, edgecolor='white', linewidth=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for i, (train_val, test_val) in enumerate(zip(train_rmse_values, test_rmse_values)):\n",
    "    plt.text(i - width/2, train_val + train_val*0.01, f'{train_val:.1f}', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    plt.text(i + width/2, test_val + test_val*0.01, f'{test_val:.1f}', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.title('RMSE: Training vs Test', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('RMSE', fontsize=12, color='#333333')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Training vs Test MAE (subplot 2)\n",
    "plt.subplot(2, 2, 2)\n",
    "train_mae_values = [baseline_train_mae, baseline_better_train_mae, baseline_best_train_mae, seasonal_train_mae]\n",
    "test_mae_values = [baseline_test_mae, baseline_better_test_mae, baseline_best_test_mae, seasonal_test_mae]\n",
    "\n",
    "bars3 = plt.bar(x - width/2, train_mae_values, width, label='Train MAE', \n",
    "                color=[c for c in colors], alpha=0.7, edgecolor='white', linewidth=0.8)\n",
    "bars4 = plt.bar(x + width/2, test_mae_values, width, label='Test MAE',\n",
    "                color=[c for c in colors], alpha=1.0, edgecolor='white', linewidth=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for i, (train_val, test_val) in enumerate(zip(train_mae_values, test_mae_values)):\n",
    "    plt.text(i - width/2, train_val + train_val*0.01, f'{train_val:.1f}', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    plt.text(i + width/2, test_val + test_val*0.01, f'{test_val:.1f}', \n",
    "             ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "plt.title('MAE: Training vs Test', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('MAE', fontsize=12, color='#333333')\n",
    "plt.xticks(x, models)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# RMSE Overfitting Gap (subplot 3)\n",
    "plt.subplot(2, 2, 3)\n",
    "rmse_gap_values = [baseline_rmse_gap, baseline_better_rmse_gap, baseline_best_rmse_gap, seasonal_rmse_gap]\n",
    "bars5 = plt.bar(models, rmse_gap_values, color=colors,\n",
    "                edgecolor='white', linewidth=0.8, width=0.7)\n",
    "\n",
    "# Add value labels and color coding for gap severity\n",
    "for i, (bar, gap) in enumerate(zip(bars5, rmse_gap_values)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.02,\n",
    "            f'{height:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    # Color code the gap severity\n",
    "    if gap > 50:\n",
    "        bar.set_alpha(1.0)  # High overfitting\n",
    "    elif gap > 30:\n",
    "        bar.set_alpha(0.8)  # Moderate overfitting\n",
    "    else:\n",
    "        bar.set_alpha(0.6)  # Low overfitting\n",
    "\n",
    "plt.title('RMSE Overfitting Gap\\n(Test - Train)', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('RMSE Gap', fontsize=12, color='#333333')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add gap severity indicators\n",
    "if max(rmse_gap_values) > 30:\n",
    "    plt.axhline(y=30, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.text(len(models)-0.5, 32, 'Moderate', ha='center', va='bottom', color='orange', fontsize=9)\n",
    "if max(rmse_gap_values) > 50:\n",
    "    plt.axhline(y=50, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.text(len(models)-0.5, 52, 'High', ha='center', va='bottom', color='red', fontsize=9)\n",
    "\n",
    "# MAE Overfitting Gap (subplot 4)\n",
    "plt.subplot(2, 2, 4)\n",
    "mae_gap_values = [baseline_mae_gap, baseline_better_mae_gap, baseline_best_mae_gap, seasonal_mae_gap]\n",
    "bars6 = plt.bar(models, mae_gap_values, color=colors,\n",
    "                edgecolor='white', linewidth=0.8, width=0.7)\n",
    "\n",
    "# Add value labels and color coding for gap severity\n",
    "for i, (bar, gap) in enumerate(zip(bars6, mae_gap_values)):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + height*0.02,\n",
    "            f'{height:.2f}', ha='center', va='bottom', fontweight='bold', fontsize=11)\n",
    "    \n",
    "    # Color code the gap severity (MAE thresholds are typically lower)\n",
    "    if gap > 35:\n",
    "        bar.set_alpha(1.0)  # High overfitting\n",
    "    elif gap > 20:\n",
    "        bar.set_alpha(0.8)  # Moderate overfitting\n",
    "    else:\n",
    "        bar.set_alpha(0.6)  # Low overfitting\n",
    "\n",
    "plt.title('MAE Overfitting Gap\\n(Test - Train)', fontsize=14, pad=20, fontweight='bold', color='#333333')\n",
    "plt.ylabel('MAE Gap', fontsize=12, color='#333333')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "# Add gap severity indicators\n",
    "if max(mae_gap_values) > 20:\n",
    "    plt.axhline(y=20, color='orange', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.text(len(models)-0.5, 22, 'Moderate', ha='center', va='bottom', color='orange', fontsize=9)\n",
    "if max(mae_gap_values) > 35:\n",
    "    plt.axhline(y=35, color='red', linestyle='--', alpha=0.5, linewidth=1)\n",
    "    plt.text(len(models)-0.5, 37, 'High', ha='center', va='bottom', color='red', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print comprehensive overfitting analysis\n",
    "print(\"Model Progression: Overfitting Analysis Summary\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Model':<15} {'RMSE Gap':<12} {'MAE Gap':<12} {'RMSE Status':<15} {'MAE Status':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Define status function\n",
    "def get_overfitting_status(gap, high_threshold, moderate_threshold):\n",
    "    if gap > high_threshold:\n",
    "        return \"High\"\n",
    "    elif gap > moderate_threshold:\n",
    "        return \"Moderate\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "model_names = ['Baseline', 'Baseline Better', 'Baseline Best', 'Seasonal']\n",
    "for i, model in enumerate(model_names):\n",
    "    rmse_gap = rmse_gap_values[i]\n",
    "    mae_gap = mae_gap_values[i]\n",
    "    rmse_status = get_overfitting_status(rmse_gap, 50, 30)\n",
    "    mae_status = get_overfitting_status(mae_gap, 35, 20)\n",
    "    \n",
    "    print(f\"{model:<15} {rmse_gap:<12.2f} {mae_gap:<12.2f} {rmse_status:<15} {mae_status:<15}\")\n",
    "\n",
    "# Calculate improvements in overfitting (vs baseline model)\n",
    "print(f\"\\nOverfitting Reduction Progress (vs Baseline Model):\")\n",
    "print(\"-\" * 55)\n",
    "for i, model in enumerate(['Baseline Better', 'Baseline Best', 'Seasonal']):\n",
    "    rmse_reduction = ((baseline_rmse_gap - rmse_gap_values[i+1]) / baseline_rmse_gap) * 100\n",
    "    mae_reduction = ((baseline_mae_gap - mae_gap_values[i+1]) / baseline_mae_gap) * 100\n",
    "    print(f\"{model:<15} RMSE: {rmse_reduction:+6.1f}% | MAE: {mae_reduction:+6.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can we train separate seaonal models and use as an ensemble approach to acheive a better result?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_split_seasonal_data():\n",
    "    \"\"\"Load Seoul bike data and create seasonal splits\"\"\"\n",
    "    # Load data\n",
    "    seoul_bike_sharing_demand = fetch_ucirepo(id=560)\n",
    "    df = seoul_bike_sharing_demand.data.features.copy()\n",
    "    df['Date'] = pd.to_datetime(df['Date'], dayfirst=True)\n",
    "    \n",
    "    # Add cyclical features\n",
    "    df['Month'] = df['Date'].dt.month\n",
    "    df['Day'] = df['Date'].dt.day\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    df_encoded = create_cyclical_encoding(df)\n",
    "    \n",
    "    # Define season boundaries (matching our analysis)\n",
    "    seasons = {\n",
    "        'Fall': ('2017-12-01', '2017-12-21'),\n",
    "        'Winter': ('2017-12-22', '2018-03-20'),\n",
    "        'Spring': ('2018-03-21', '2018-06-21'), \n",
    "        'Summer': ('2018-06-22', '2018-09-22'),\n",
    "        'Fall_2': ('2018-09-23', '2018-11-30')\n",
    "    }\n",
    "    \n",
    "    splits = {}\n",
    "    print(\"SEASONAL DATA SPLITS:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    for season, (start, end) in seasons.items():\n",
    "        mask = (df_encoded['Date'] >= start) & (df_encoded['Date'] <= end)\n",
    "        season_data = df_encoded[mask].copy()\n",
    "        \n",
    "        # 80/20 split\n",
    "        n_train = int(len(season_data) * 0.8)\n",
    "        train_data = season_data.iloc[:n_train]\n",
    "        test_data = season_data.iloc[n_train:]\n",
    "        \n",
    "        splits[season] = {\n",
    "            'train': train_data,\n",
    "            'test': test_data\n",
    "        }\n",
    "        \n",
    "        # Print detailed split information\n",
    "        print(f\"{season:>8}: {n_train:4d} train, {len(test_data):3d} test | \"\n",
    "              f\"Train: {train_data['Date'].min().strftime('%m/%d')} - {train_data['Date'].max().strftime('%m/%d')} | \"\n",
    "              f\"Test: {test_data['Date'].min().strftime('%m/%d')} - {test_data['Date'].max().strftime('%m/%d')}\")\n",
    "    \n",
    "    # Show total\n",
    "    total_train = sum(len(s['train']) for s in splits.values())\n",
    "    total_test = sum(len(s['test']) for s in splits.values())\n",
    "    print(f\"{'TOTAL':>8}: {total_train:4d} train, {total_test:3d} test\")\n",
    "    \n",
    "    return splits\n",
    "\n",
    "splits = load_and_split_seasonal_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seasonal_ensemble(splits):\n",
    "    \"\"\"Train separate XGBoost model for each season\"\"\"\n",
    "    # Conservative parameters (limited data per season)\n",
    "    params = {\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 75,\n",
    "        'min_child_weight': 15,\n",
    "        'reg_alpha': 3.0,\n",
    "        'reg_lambda': 5.0,\n",
    "        'subsample': 0.6,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    models = {}\n",
    "    results = {}\n",
    "    \n",
    "    # Feature columns\n",
    "    exclude_cols = ['Date', 'Rented Bike Count', 'Seasons', 'Holiday']\n",
    "    feature_cols = [col for col in splits['Winter']['train'].columns if col not in exclude_cols]\n",
    "    \n",
    "    for season, data in splits.items():\n",
    "        if season == 'Fall_2':  # Skip duplicate fall\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nTraining {season} model...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X_train = data['train'][feature_cols].select_dtypes(include=[np.number])\n",
    "        y_train = data['train']['Rented Bike Count']\n",
    "        X_test = data['test'][feature_cols].select_dtypes(include=[np.number])\n",
    "        y_test = data['test']['Rented Bike Count']\n",
    "        \n",
    "        # Scale and train\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate with MAE as primary metric\n",
    "        test_preds = model.predict(X_test_scaled)\n",
    "        test_mae = mean_absolute_error(y_test, test_preds)\n",
    "        test_rmse = math.sqrt(mean_squared_error(y_test, test_preds))\n",
    "        test_r2 = r2_score(y_test, test_preds)\n",
    "        \n",
    "        models[season] = model\n",
    "        results[season] = {\n",
    "            'test_mae': test_mae,\n",
    "            'test_rmse': test_rmse, \n",
    "            'test_r2': test_r2\n",
    "        }\n",
    "        print(f\"  {season}: MAE={test_mae:.1f}, RMSE={test_rmse:.1f}, R²={test_r2:.3f}\")\n",
    "    \n",
    "    return models, results\n",
    "\n",
    "seasonal_models, seasonal_results = train_seasonal_ensemble(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_seasonal_ensemble(splits):\n",
    "    \"\"\"Train separate XGBoost model for each season\"\"\"\n",
    "    # Conservative parameters (limited data per season)\n",
    "    params = {\n",
    "        'max_depth': 3,\n",
    "        'learning_rate': 0.1,\n",
    "        'n_estimators': 75,\n",
    "        'min_child_weight': 15,\n",
    "        'reg_alpha': 3.0,\n",
    "        'reg_lambda': 5.0,\n",
    "        'subsample': 0.6,\n",
    "        'colsample_bytree': 0.6,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    models = {}\n",
    "    results = {}\n",
    "    \n",
    "    # Feature columns\n",
    "    exclude_cols = ['Date', 'Rented Bike Count', 'Seasons', 'Holiday']\n",
    "    feature_cols = [col for col in splits['Winter']['train'].columns if col not in exclude_cols]\n",
    "    \n",
    "    for season, data in splits.items():\n",
    "        if season == 'Fall_2':  # Skip duplicate fall\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\nTraining {season} model...\")\n",
    "        \n",
    "        # Prepare data\n",
    "        X_train = data['train'][feature_cols].select_dtypes(include=[np.number])\n",
    "        y_train = data['train']['Rented Bike Count']\n",
    "        X_test = data['test'][feature_cols].select_dtypes(include=[np.number])\n",
    "        y_test = data['test']['Rented Bike Count']\n",
    "        \n",
    "        # Scale and train\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "        \n",
    "        model = xgb.XGBRegressor(**params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate with MAE as primary metric\n",
    "        test_preds = model.predict(X_test_scaled)\n",
    "        test_mae = mean_absolute_error(y_test, test_preds)\n",
    "        test_rmse = math.sqrt(mean_squared_error(y_test, test_preds))\n",
    "        test_r2 = r2_score(y_test, test_preds)\n",
    "        \n",
    "        models[season] = model\n",
    "        results[season] = {\n",
    "            'test_mae': test_mae,\n",
    "            'test_rmse': test_rmse, \n",
    "            'test_r2': test_r2\n",
    "        }\n",
    "        print(f\"  {season}: MAE={test_mae:.1f}, RMSE={test_rmse:.1f}, R²={test_r2:.3f}\")\n",
    "    \n",
    "    return models, results\n",
    "\n",
    "seasonal_models, seasonal_results = train_seasonal_ensemble(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_simple_baseline(splits, results):\n",
    "    \"\"\"Compare seasonal models with just predicting the training mean\"\"\"\n",
    "    \n",
    "    print(\"BASELINE COMPARISON (predict training mean):\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for season, data in splits.items():\n",
    "        if season == 'Fall_2':  # Skip duplicate fall\n",
    "            continue\n",
    "            \n",
    "        train_mean = data['train']['Rented Bike Count'].mean()\n",
    "        test_actual = data['test']['Rented Bike Count']\n",
    "        \n",
    "        # Baseline: just predict the training mean\n",
    "        baseline_preds = np.full(len(test_actual), train_mean)\n",
    "        baseline_mae = mean_absolute_error(test_actual, baseline_preds)\n",
    "        baseline_rmse = math.sqrt(mean_squared_error(test_actual, baseline_preds))\n",
    "        baseline_r2 = r2_score(test_actual, baseline_preds)\n",
    "        \n",
    "        # Seasonal model performance\n",
    "        seasonal_mae = results[season]['test_mae']\n",
    "        seasonal_rmse = results[season]['test_rmse']\n",
    "        seasonal_r2 = results[season]['test_r2']\n",
    "        \n",
    "        print(f\"{season:} Mean Baseline  MAE={baseline_mae:.1f}, RMSE={baseline_rmse:.1f}, R²={baseline_r2:.3f}\")\n",
    "        print(f\"         {season} Model MAE={seasonal_mae:.1f}, RMSE={seasonal_rmse:.1f}, R²={seasonal_r2:.3f}\")\n",
    "        print(f\"         Improvement:   {baseline_mae - seasonal_mae:+6.1f} MAE, {baseline_rmse - seasonal_rmse:+6.1f} RMSE, {seasonal_r2 - baseline_r2:+.3f} R²\")\n",
    "        print()\n",
    "        \n",
    "compare_with_simple_baseline(splits, seasonal_results)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing an ensemble of individual season models with a single seasonal model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ensemble average performance\n",
    "avg_seasonal_mae = np.mean([r['test_mae'] for r in seasonal_results.values()])\n",
    "avg_seasonal_rmse = np.mean([r['test_rmse'] for r in seasonal_results.values()])\n",
    "avg_seasonal_r2 = np.mean([r['test_r2'] for r in seasonal_results.values()])\n",
    "\n",
    "# Show the comparison\n",
    "print(f\"{'Approach':<25} {'MAE':<8} {'RMSE':<8} {'R²':<8} {'Data Used'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Single Seasonal Model':<25} {seasonal_test_mae:<8.1f} {seasonal_test_rmse:<8.1f} {seasonal_test_r2:<8.3f} Full dataset (8,760 hrs)\")\n",
    "print(f\"{'Seasonal Ensemble Avg':<25} {avg_seasonal_mae:<8.1f} {avg_seasonal_rmse:<8.1f} {avg_seasonal_r2:<8.3f} Split by season\")\n",
    "\n",
    "# Individual seasonal model performance for context\n",
    "print(f\"\\nIndividual Seasonal Model Performance:\")\n",
    "print(\"-\" * 45)\n",
    "for season, results in seasonal_results.items():\n",
    "    train_samples = len(splits[season]['train'])\n",
    "    test_samples = len(splits[season]['test'])\n",
    "    print(f\"{season:>8}: MAE={results['test_mae']:6.1f}, R²={results['test_r2']:6.3f} \"\n",
    "          f\"({train_samples:,} train samples)\")\n",
    "\n",
    "# Determine winner\n",
    "mae_difference = avg_seasonal_mae - seasonal_test_mae\n",
    "\n",
    "if mae_difference > 0:\n",
    "    print(f\"\\nSINGLE SEASONAL MODEL WINS by {mae_difference:.1f} MAE\")\n",
    "    print(f\"\\nWhy the single model is superior:\")\n",
    "    print(f\"  • Uses full dataset: 8,760 hours vs {min([len(s['train']) for s in splits.values() if 'Fall_2' not in s]):,}-{max([len(s['train']) for s in splits.values() if 'Fall_2' not in s]):,} per season\")\n",
    "    print(f\"  • Learns temporal patterns across seasons\")\n",
    "    print(f\"  • Benefits from seasonal transitions and cross-seasonal features\")\n",
    "    print(f\"  • Grid search + early stopping + manual tuning\")\n",
    "    print(f\"  • Better generalization with {seasonal_test_rmse:.1f} RMSE vs {avg_seasonal_rmse:.1f} average\")\n",
    "else:\n",
    "    print(f\"\\nSEASONAL ENSEMBLE WINS by {abs(mae_difference):.1f} MAE\")\n",
    "    print(f\"Seasonal specialization overcomes data limitations\")\n",
    "\n",
    "# Fundamental problem with seasonal approach\n",
    "min_samples = min([len(s['train']) for s in splits.values() if 'Fall_2' not in s])\n",
    "total_samples = len(y_train)\n",
    "\n",
    "print(f\"\\nFUNDAMENTAL LIMITATION:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Smallest seasonal training set: {min_samples:,} samples ({min_samples/total_samples*100:.1f}% of full dataset)\")\n",
    "print(f\"Single model training set:      {total_samples:,} samples (100% of full dataset)\")\n",
    "print(f\"Data efficiency ratio:          {total_samples/min_samples:.1f}x more data for single model\")\n",
    "\n",
    "print(f\"\\nCONCLUSION:\")\n",
    "print(\"-\" * 15)\n",
    "print(f\"Use SINGLE SEASONAL MODEL for production\")\n",
    "print(f\"   - Superior performance across all metrics\")\n",
    "print(f\"   - Leverages full dataset for better learning\") \n",
    "print(f\"   - Captures cross-seasonal patterns and transitions\")\n",
    "print(f\"   - More robust with comprehensive tuning approach\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "yFkCZCB2WsRp",
    "x6hwTLKoW-d_",
    "QhRPHn3wXK2V"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
