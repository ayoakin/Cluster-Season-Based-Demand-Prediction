{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Notebook Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cyclical_encoding(X_data):\n",
    "    X_cyclical = X_data.copy()\n",
    "    X_cyclical['Date'] = pd.to_datetime(X_cyclical['Date'])\n",
    "    X_cyclical['Month_sin'] = np.sin(2 * np.pi * X_cyclical['Month'] / 12)\n",
    "    X_cyclical['Month_cos'] = np.cos(2 * np.pi * X_cyclical['Month'] / 12)\n",
    "    X_cyclical['DayOfYear'] = X_cyclical['Date'].dt.dayofyear\n",
    "    X_cyclical['DayOfYear_sin'] = np.sin(2 * np.pi * X_cyclical['DayOfYear'] / 365)\n",
    "    X_cyclical['DayOfYear_cos'] = np.cos(2 * np.pi * X_cyclical['DayOfYear'] / 365)\n",
    "    X_cyclical['Hour_sin'] = np.sin(2 * np.pi * X_cyclical['Hour'] / 24)\n",
    "    X_cyclical['Hour_cos'] = np.cos(2 * np.pi * X_cyclical['Hour'] / 24)\n",
    "    X_cyclical['DayOfWeek_sin'] = np.sin(2 * np.pi * X_cyclical['DayOfWeek'] / 7)\n",
    "    X_cyclical['DayOfWeek_cos'] = np.cos(2 * np.pi * X_cyclical['DayOfWeek'] / 7)\n",
    "    \n",
    "    # Seasonal mapping and encoding\n",
    "    season_mapping = {'Winter': 0, 'Spring': 1, 'Summer': 2, 'Autumn': 3}\n",
    "    X_cyclical['Season_numeric'] = X_cyclical['Seasons'].map(season_mapping)\n",
    "    X_cyclical['Season_sin'] = np.sin(2 * np.pi * X_cyclical['Season_numeric'] / 4)\n",
    "    X_cyclical['Season_cos'] = np.cos(2 * np.pi * X_cyclical['Season_numeric'] / 4)\n",
    "    \n",
    "    return X_cyclical\n",
    "\n",
    "def preprocess_data():\n",
    "    \"\"\"Enhanced preprocessing with cyclical encoding\"\"\"\n",
    "    seoul_bike_sharing_demand = fetch_ucirepo(id=560)\n",
    "    X_original = seoul_bike_sharing_demand.data.features\n",
    "    y_original = seoul_bike_sharing_demand.data.targets\n",
    "    \n",
    "    if 'Rented Bike Count' in X_original.columns:\n",
    "        y = X_original[['Rented Bike Count']]\n",
    "        X = X_original.drop('Rented Bike Count', axis=1)\n",
    "        X = pd.concat([X, y_original], axis=1)\n",
    "    else:\n",
    "        y = y_original\n",
    "        X = X_original\n",
    "        \n",
    "    if 'Date' in X.columns:\n",
    "        X['Date'] = pd.to_datetime(X['Date'], format='%d/%m/%Y')\n",
    "        X['Year'] = X['Date'].dt.year\n",
    "        X['Month'] = X['Date'].dt.month\n",
    "        X['Day'] = X['Date'].dt.day\n",
    "        X['DayOfWeek'] = X['Date'].dt.dayofweek\n",
    "        \n",
    "    X = create_cyclical_encoding(X)\n",
    "    X = X.drop('Date', axis=1)\n",
    "    X = pd.get_dummies(X, drop_first=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    definitely_remove = [\"DayOfYear\", \"Month\", \"Day\", \"Dew point temperature\"]\n",
    "    actually_removed = [f for f in definitely_remove if f in X_train.columns]\n",
    "    \n",
    "    if actually_removed:\n",
    "        X_train = X_train.drop(columns=actually_removed)\n",
    "        X_test = X_test.drop(columns=actually_removed)\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, X_train.columns.tolist()\n",
    "\n",
    "def mahalanobis_distance(x, y, inv_cov):\n",
    "    return mahalanobis(x, y, inv_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data with cyclical encoding\n",
    "print(\"=== CYCLICAL ENCODING + CLUSTERING EXPERIMENT ===\")\n",
    "print(\"Loading and preprocessing data with cyclical features...\")\n",
    "X_train_scaled, X_test_scaled, y_train, y_test, scaler, feature_names = preprocess_data()\n",
    "print(f\"Data preprocessed: {len(feature_names)} features, {len(X_train_scaled)} training samples\")\n",
    "\n",
    "# 1. BASELINE: Single model with cyclical encoding\n",
    "print(\"\\n1. BASELINE: Single XGBoost model with cyclical encoding\")\n",
    "baseline_cyclical_model = xgb.XGBRegressor(random_state=42)\n",
    "baseline_cyclical_model.fit(X_train_scaled, y_train.values.ravel())\n",
    "baseline_cyclical_preds = baseline_cyclical_model.predict(X_test_scaled)\n",
    "\n",
    "baseline_cyclical_metrics = {\n",
    "    'rmse': math.sqrt(mean_squared_error(y_test, baseline_cyclical_preds)),\n",
    "    'r2': r2_score(y_test, baseline_cyclical_preds),\n",
    "    'mae': mean_absolute_error(y_test, baseline_cyclical_preds)\n",
    "}\n",
    "\n",
    "print(f\"Baseline Cyclical Model - RMSE: {baseline_cyclical_metrics['rmse']:.2f}, \"\n",
    "      f\"RÂ²: {baseline_cyclical_metrics['r2']:.4f}, MAE: {baseline_cyclical_metrics['mae']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Cluster on Cyclical-Encoded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CLUSTERING on cyclical-encoded features\n",
    "print(\"\\n2. CLUSTERING on cyclical-encoded features\")\n",
    "\n",
    "# Euclidean clustering\n",
    "print(\"Performing Euclidean K-means clustering on cyclical features...\")\n",
    "euclidean_kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "euclidean_clusters = euclidean_kmeans.fit_predict(X_train_scaled)\n",
    "\n",
    "# Mahalanobis clustering\n",
    "print(\"Performing Mahalanobis distance-based clustering...\")\n",
    "cov = np.cov(X_train_scaled, rowvar=False)\n",
    "cov += np.eye(cov.shape[0]) * 1e-6\n",
    "inv_cov = np.linalg.inv(cov)\n",
    "\n",
    "# Initialize with Euclidean results and refine with Mahalanobis\n",
    "mahalanobis_clusters = euclidean_kmeans.predict(X_train_scaled)\n",
    "centroids = np.array([X_train_scaled[mahalanobis_clusters == i].mean(axis=0) for i in range(3)])\n",
    "\n",
    "for iteration in range(5):\n",
    "    for i, point in enumerate(X_train_scaled):\n",
    "        distances = [mahalanobis_distance(point, centroid, inv_cov) for centroid in centroids]\n",
    "        mahalanobis_clusters[i] = np.argmin(distances)\n",
    "    \n",
    "    for i in range(3):\n",
    "        if sum(mahalanobis_clusters == i) > 0:\n",
    "            centroids[i] = X_train_scaled[mahalanobis_clusters == i].mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Train Cluster Specific Models with Cyclical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_models = []\n",
    "mahalanobis_models = []\n",
    "\n",
    "for i in range(3):\n",
    "    # Euclidean cluster models\n",
    "    cluster_indices = euclidean_clusters == i\n",
    "    if sum(cluster_indices) > 0:\n",
    "        print(f\"Training Euclidean cluster {i} model with {sum(cluster_indices)} samples\")\n",
    "        model = xgb.XGBRegressor(random_state=42)\n",
    "        model.fit(X_train_scaled[cluster_indices], y_train.iloc[cluster_indices].values.ravel())\n",
    "        euclidean_models.append(model)\n",
    "    else:\n",
    "        euclidean_models.append(None)\n",
    "    \n",
    "    # Mahalanobis cluster models\n",
    "    cluster_indices = mahalanobis_clusters == i\n",
    "    if sum(cluster_indices) > 0:\n",
    "        print(f\"Training Mahalanobis cluster {i} model with {sum(cluster_indices)} samples\")\n",
    "        model = xgb.XGBRegressor(random_state=42)\n",
    "        model.fit(X_train_scaled[cluster_indices], y_train.iloc[cluster_indices].values.ravel())\n",
    "        mahalanobis_models.append(model)\n",
    "    else:\n",
    "        mahalanobis_models.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Euclidean and Mahalamobis Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign test samples to clusters\n",
    "euclidean_test_clusters = euclidean_kmeans.predict(X_test_scaled)\n",
    "mahalanobis_test_clusters = np.zeros(len(X_test_scaled), dtype=int)\n",
    "\n",
    "for i, point in enumerate(X_test_scaled):\n",
    "    distances = [mahalanobis_distance(point, centroid, inv_cov) for centroid in centroids]\n",
    "    mahalanobis_test_clusters[i] = np.argmin(distances)\n",
    "\n",
    "# Make predictions\n",
    "euclidean_preds = np.zeros(len(y_test))\n",
    "mahalanobis_preds = np.zeros(len(y_test))\n",
    "\n",
    "for i in range(3):\n",
    "    # Euclidean predictions\n",
    "    cluster_indices = euclidean_test_clusters == i\n",
    "    if sum(cluster_indices) > 0 and euclidean_models[i] is not None:\n",
    "        euclidean_preds[cluster_indices] = euclidean_models[i].predict(X_test_scaled[cluster_indices])\n",
    "    \n",
    "    # Mahalanobis predictions\n",
    "    cluster_indices = mahalanobis_test_clusters == i\n",
    "    if sum(cluster_indices) > 0 and mahalanobis_models[i] is not None:\n",
    "        mahalanobis_preds[cluster_indices] = mahalanobis_models[i].predict(X_test_scaled[cluster_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Calculate Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_cyclical_metrics = {\n",
    "    'rmse': math.sqrt(mean_squared_error(y_test, euclidean_preds)),\n",
    "    'r2': r2_score(y_test, euclidean_preds),\n",
    "    'mae': mean_absolute_error(y_test, euclidean_preds)\n",
    "}\n",
    "\n",
    "mahalanobis_cyclical_metrics = {\n",
    "    'rmse': math.sqrt(mean_squared_error(y_test, mahalanobis_preds)),\n",
    "    'r2': r2_score(y_test, mahalanobis_preds),\n",
    "    'mae': mean_absolute_error(y_test, mahalanobis_preds)\n",
    "}\n",
    "\n",
    "# 6. RESULTS COMPARISON\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Baseline Cyclical', 'Euclidean + Cyclical', 'Mahalanobis + Cyclical'],\n",
    "    'RMSE': [baseline_cyclical_metrics['rmse'], euclidean_cyclical_metrics['rmse'], mahalanobis_cyclical_metrics['rmse']],\n",
    "    'RÂ²': [baseline_cyclical_metrics['r2'], euclidean_cyclical_metrics['r2'], mahalanobis_cyclical_metrics['r2']],  \n",
    "    'MAE': [baseline_cyclical_metrics['mae'], euclidean_cyclical_metrics['mae'], mahalanobis_cyclical_metrics['mae']]\n",
    "})\n",
    "\n",
    "print(results_df.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### Improvements vs Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model_name in enumerate(['Euclidean + Cyclical', 'Mahalanobis + Cyclical']):\n",
    "    if i == 0:\n",
    "        metrics = euclidean_cyclical_metrics\n",
    "    else:\n",
    "        metrics = mahalanobis_cyclical_metrics\n",
    "    \n",
    "    rmse_improvement = ((baseline_cyclical_metrics['rmse'] - metrics['rmse']) / baseline_cyclical_metrics['rmse']) * 100\n",
    "    r2_improvement = ((metrics['r2'] - baseline_cyclical_metrics['r2']) / baseline_cyclical_metrics['r2']) * 100  \n",
    "    mae_improvement = ((baseline_cyclical_metrics['mae'] - metrics['mae']) / baseline_cyclical_metrics['mae']) * 100\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  RMSE: {rmse_improvement:+6.2f}%\")\n",
    "    print(f\"  RÂ²:   {r2_improvement:+6.2f}%\") \n",
    "    print(f\"  MAE:  {mae_improvement:+6.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "### Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"CLUSTER ANALYSIS (with cyclical features):\")\n",
    "\n",
    "print(\"\\nCluster sizes:\")\n",
    "for i in range(3):\n",
    "    euc_size = sum(euclidean_clusters == i)\n",
    "    mah_size = sum(mahalanobis_clusters == i)\n",
    "    print(f\"Cluster {i}: Euclidean={euc_size}, Mahalanobis={mah_size}\")\n",
    "\n",
    "print(\"\\nAverage bike count per cluster:\")\n",
    "for i in range(3):\n",
    "    euc_indices = euclidean_clusters == i\n",
    "    mah_indices = mahalanobis_clusters == i\n",
    "    \n",
    "    if sum(euc_indices) > 0:\n",
    "        euc_avg = y_train.iloc[euc_indices].values.mean()\n",
    "        print(f\"Euclidean Cluster {i}: {euc_avg:.1f} bikes\")\n",
    "    \n",
    "    if sum(mah_indices) > 0:\n",
    "        mah_avg = y_train.iloc[mah_indices].values.mean()\n",
    "        print(f\"Mahalanobis Cluster {i}: {mah_avg:.1f} bikes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': baseline_cyclical_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Show top cyclical features\n",
    "cyclical_features = feature_importance[feature_importance['feature'].str.contains('_sin|_cos')].head(8)\n",
    "print(\"Top cyclical features:\")\n",
    "for i, (_, row) in enumerate(cyclical_features.iterrows(), 1):\n",
    "    print(f\"  {i}. {row['feature']:<20s}: {row['importance']:.4f}\")\n",
    "\n",
    "cyclical_importance_sum = cyclical_features['importance'].sum()\n",
    "total_importance = feature_importance['importance'].sum()\n",
    "cyclical_percentage = (cyclical_importance_sum / total_importance) * 100\n",
    "print(f\"\\nCyclical features account for {cyclical_percentage:.1f}% of total importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = results_df.loc[results_df['RMSE'].idxmin(), 'Model']\n",
    "best_rmse = results_df['RMSE'].min()\n",
    "baseline_rmse = baseline_cyclical_metrics['rmse']\n",
    "\n",
    "if best_rmse < baseline_rmse:\n",
    "    improvement = ((baseline_rmse - best_rmse) / baseline_rmse) * 100\n",
    "    print(f\"The {best_model} model has a {improvement:.2f}% RMSE improvement\")\n",
    "    print(f\"  The combination of cyclical encoding + clustering provides measurable benefit\")\n",
    "else:\n",
    "    degradation = ((best_rmse - baseline_rmse) / baseline_rmse) * 100\n",
    "    print(f\"The Baseline cyclical model has the better RMSE score\")\n",
    "    print(f\"  Cyclical encoding alone captures the temporal patterns effectively\")\n",
    "\n",
    "print(f\"\\nKey Finding: Cyclical features represent {cyclical_percentage:.1f}% of model importance,\")\n",
    "print(f\"suggesting temporal patterns are the dominant signal in bike demand prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
